{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Ah1Os8TAItF42rLtAINNJfaqDJYXRJ7X","timestamp":1707941883123},{"file_id":"1BFKIX_hw2Vvq0AZiASTRa_4v3QfSolS2","timestamp":1707735542988},{"file_id":"1CW4IAAki_GHAoO9lko3CYbJPBdwKehqD","timestamp":1707677655458},{"file_id":"1zbt2A74kM10HvcAEgEy3fGgRSNyHZQKj","timestamp":1707638840755},{"file_id":"1esHcdn0jL8an4SMG23_fMjbK9n-MsWXz","timestamp":1601876029717},{"file_id":"1lnvSzcjmmJknvRG05fk1BMis7fyE0i9C","timestamp":1601844968812},{"file_id":"1yz-_veyTWMbt3pE1SFyWH-ZoA_AqiImd","timestamp":1601781455461},{"file_id":"13qcZDBvQzxXshmMspv0SBJm9-85GRO31","timestamp":1601644081170}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JvkoC8rAYBE7"},"source":["\n","##Setup\n","\n","\n","You will need to make a copy of this Colab notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**.\n","\n","Please complete the code with **TODO** marks\n"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"oVIFC1nfKvRY"}},{"cell_type":"markdown","source":["First, we import and download the Omniglot dataset"],"metadata":{"id":"qx4VL1fVkoIJ"}},{"cell_type":"code","metadata":{"id":"RBkP5aBdfFkd","executionInfo":{"status":"ok","timestamp":1707942743413,"user_tz":-60,"elapsed":282,"user":{"displayName":"DANI asensi","userId":"03754562011649161128"}}},"source":["import os\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","# Need to download the Omniglot dataset -- DON'T MODIFY THIS CELL\n","if not os.path.isdir('./omniglot_resized'):\n","    gdd.download_file_from_google_drive(file_id='1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI',\n","                                        dest_path='./omniglot_resized.zip',\n","                                        unzip=True)\n","\n","assert os.path.isdir('./omniglot_resized')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMtiYUiwI-1K","executionInfo":{"status":"ok","timestamp":1707942743705,"user_tz":-60,"elapsed":4,"user":{"displayName":"DANI asensi","userId":"03754562011649161128"}}},"source":["\"\"\" Utility functions. \"\"\"\n","## NOTE: You do not need to modify this block but you will need to use it.\n","import numpy as np\n","import os\n","import random\n","import tensorflow as tf\n","\n","## Loss utilities\n","def cross_entropy_loss(pred, label, k_shot):\n","    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=tf.stop_gradient(label)) / k_shot)\n","\n","def accuracy(labels, predictions):\n","  return tf.reduce_mean(tf.cast(tf.equal(labels, predictions), dtype=tf.float32))\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Omniglot data loading"],"metadata":{"id":"5rZwTual-lKX"}},{"cell_type":"code","metadata":{"id":"wXZS_JULriBh","executionInfo":{"status":"ok","timestamp":1707942743706,"user_tz":-60,"elapsed":4,"user":{"displayName":"DANI asensi","userId":"03754562011649161128"}}},"source":["\"\"\"Data loading scripts\"\"\"\n","## NOTE: You do not need to modify this block but you will need to use it.\n","import numpy as np\n","import os\n","import random\n","import tensorflow as tf\n","from scipy import misc\n","import imageio\n","\n","def get_images(paths, labels, n_samples=None, shuffle=True):\n","  \"\"\"\n","  Takes a set of character folders and labels and returns paths to image files\n","  paired with labels.\n","  Args:\n","    paths: A list of character folders\n","    labels: List or numpy array of same length as paths\n","    n_samples: Number of images to retrieve per character\n","  Returns:\n","    List of (label, image_path) tuples\n","  \"\"\"\n","  if n_samples is not None:\n","    sampler = lambda x: random.sample(x, n_samples)\n","  else:\n","    sampler = lambda x: x\n","  images_labels = [(i, os.path.join(path, image))\n","           for i, path in zip(labels, paths)\n","           for image in sampler(os.listdir(path))]\n","  if shuffle:\n","    random.shuffle(images_labels)\n","  return images_labels\n","\n","\n","def image_file_to_array(filename, dim_input):\n","  \"\"\"\n","  Takes an image path and returns numpy array\n","  Args:\n","    filename: Image filename\n","    dim_input: Flattened shape of image\n","  Returns:\n","    1 channel image\n","  \"\"\"\n","  image = imageio.v2.imread(filename)\n","  image = image.reshape([dim_input])\n","  image = image.astype(np.float32) / 255.0\n","  image = 1.0 - image\n","  return image\n","\n","\n","class DataGenerator(object):\n","  \"\"\"\n","  Data Generator capable of generating batches of Omniglot data.\n","  A \"class\" is considered a class of omniglot digits.\n","  \"\"\"\n","\n","  def __init__(self, num_classes, num_samples_per_class, num_meta_test_classes, num_meta_test_samples_per_class, config={}):\n","    \"\"\"\n","    Args:\n","      num_classes: Number of classes for classification (K-way)\n","      num_samples_per_class: num samples to generate per class in one batch\n","      num_meta_test_classes: Number of classes for classification (K-way) at meta-test time\n","      num_meta_test_samples_per_class: num samples to generate per class in one batch at meta-test time\n","      batch_size: size of meta batch size (e.g. number of functions)\n","    \"\"\"\n","    self.num_samples_per_class = num_samples_per_class\n","    self.num_classes = num_classes\n","    self.num_meta_test_samples_per_class = num_meta_test_samples_per_class\n","    self.num_meta_test_classes = num_meta_test_classes\n","\n","    data_folder = config.get('data_folder', './omniglot_resized')\n","    self.img_size = config.get('img_size', (28, 28))\n","\n","    self.dim_input = np.prod(self.img_size)\n","    self.dim_output = self.num_classes\n","\n","    character_folders = [os.path.join(data_folder, family, character)\n","               for family in os.listdir(data_folder)\n","               if os.path.isdir(os.path.join(data_folder, family))\n","               for character in os.listdir(os.path.join(data_folder, family))\n","               if os.path.isdir(os.path.join(data_folder, family, character))]\n","\n","    random.seed(123)\n","    random.shuffle(character_folders)\n","    num_val = 100\n","    num_train = 1100\n","    self.metatrain_character_folders = character_folders[: num_train]\n","    self.metaval_character_folders = character_folders[\n","      num_train:num_train + num_val]\n","    self.metatest_character_folders = character_folders[\n","      num_train + num_val:]\n","\n","  def sample_batch(self, batch_type, batch_size, shuffle=True, swap=False):\n","    \"\"\"\n","    Samples a batch for training, validation, or testing\n","    Args:\n","      batch_type: meta_train/meta_val/meta_test\n","      shuffle: randomly shuffle classes or not\n","      swap: swap number of classes (N) and number of samples per class (K) or not\n","    Returns:\n","      A a tuple of (1) Image batch and (2) Label batch where\n","      image batch has shape [B, N, K, 784] and label batch has shape [B, N, K, N] if swap is False\n","      where B is batch size, K is number of samples per class, N is number of classes\n","    \"\"\"\n","    if batch_type == \"meta_train\":\n","      folders = self.metatrain_character_folders\n","      num_classes = self.num_classes\n","      num_samples_per_class = self.num_samples_per_class\n","    elif batch_type == \"meta_val\":\n","      folders = self.metaval_character_folders\n","      num_classes = self.num_classes\n","      num_samples_per_class = self.num_samples_per_class\n","    else:\n","      folders = self.metatest_character_folders\n","      num_classes = self.num_meta_test_classes\n","      num_samples_per_class = self.num_meta_test_samples_per_class\n","    all_image_batches, all_label_batches = [], []\n","    for i in range(batch_size):\n","      sampled_character_folders = random.sample(\n","        folders, num_classes)\n","      labels_and_images = get_images(sampled_character_folders, range(\n","        num_classes), n_samples=num_samples_per_class, shuffle=False)\n","      labels = [li[0] for li in labels_and_images]\n","      images = [image_file_to_array(\n","        li[1], self.dim_input) for li in labels_and_images]\n","      images = np.stack(images)\n","      labels = np.array(labels).astype(np.int32)\n","      labels = np.reshape(\n","        labels, (num_classes, num_samples_per_class))\n","      labels = np.eye(num_classes, dtype=np.float32)[labels]\n","      images = np.reshape(\n","        images, (num_classes, num_samples_per_class, -1))\n","\n","      batch = np.concatenate([labels, images], 2)\n","      if shuffle:\n","        for p in range(num_samples_per_class):\n","          np.random.shuffle(batch[:, p])\n","\n","      labels = batch[:, :, :num_classes]\n","      images = batch[:, :, num_classes:]\n","\n","      if swap:\n","        labels = np.swapaxes(labels, 0, 1)\n","        images = np.swapaxes(images, 0, 1)\n","\n","      all_image_batches.append(images)\n","      all_label_batches.append(labels)\n","    all_image_batches = np.stack(all_image_batches)\n","    all_label_batches = np.stack(all_label_batches)\n","    return all_image_batches, all_label_batches"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Prototypical neural network. Please complete the loss function at **TODO** marks"],"metadata":{"id":"dhGD4VOBbd2-"}},{"cell_type":"code","metadata":{"id":"ohmGfgV-geFj","executionInfo":{"status":"ok","timestamp":1707942743706,"user_tz":-60,"elapsed":3,"user":{"displayName":"DANI asensi","userId":"03754562011649161128"}}},"source":["# models/ProtoNet\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","class ProtoNet(tf.keras.Model):\n","\n","  def __init__(self, num_filters, latent_dim):\n","    super(ProtoNet, self).__init__()\n","    self.num_filters = num_filters\n","    self.latent_dim = latent_dim\n","    num_filter_list = self.num_filters + [latent_dim]\n","    self.convs = []\n","    for i, num_filter in enumerate(num_filter_list):\n","      block_parts = [\n","        layers.Conv2D(\n","          filters=num_filter,\n","          kernel_size=3,\n","          padding='SAME',\n","          activation='linear'),\n","      ]\n","\n","      block_parts += [layers.BatchNormalization()]\n","      block_parts += [layers.Activation('relu')]\n","      block_parts += [layers.MaxPool2D()]\n","      block = tf.keras.Sequential(block_parts, name='conv_block_%d' % i)\n","      self.__setattr__(\"conv%d\" % i, block)\n","      self.convs.append(block)\n","    self.flatten = tf.keras.layers.Flatten()\n","\n","  def call(self, inp):\n","    out = inp\n","    for conv in self.convs:\n","      out = conv(out)\n","    out = self.flatten(out)\n","    return out\n","\n","def ProtoLoss(x_latent, q_latent, labels_onehot, num_classes, num_support, num_queries):\n","  \"\"\"\n","    calculates the prototype network loss using the latent representation of x\n","    and the latent representation of the query set\n","    Args:\n","      x_latent: latent representation of supports with shape [N*S, D], where D is the latent dimension\n","      q_latent: latent representation of queries with shape [N*Q, D], where D is the latent dimension\n","      labels_onehot: one-hot encodings of the labels of the queries with shape [N, Q, N]\n","      num_classes: number of classes (N) for classification\n","      num_support: number of examples (S) in the support set\n","      num_queries: number of examples (Q) in the query set\n","    Returns:\n","      ce_loss: the cross entropy loss between the predicted labels and true labels\n","      acc: the accuracy of classification on the queries\n","  \"\"\"\n","  #############################\n","  #### YOUR CODE GOES HERE ####\n","\n","  # Reshaping latent representations of input to prepare for prototype calculation.\n","  x_latent_reshaped = tf.reshape(x_latent, [num_classes, num_support, -1])\n","\n","  # Calculating the mean representation for each class (prototypes).\n","  prototypes = tf.reduce_mean(x_latent_reshaped, axis=1)\n","\n","  # 1. Preparing prototypes for distance calculation by repeating them across the query examples.\n","  # Expand dimensions of prototypes tensor along the first axis\n","  prototypes_expanded = tf.expand_dims(prototypes, axis=0)\n","  # Calculate the number of times to replicate prototypes along the first axis\n","  # This will be the total number of classes multiplied by the number of queries\n","  num_replications = num_classes * num_queries\n","  # Tile the expanded prototypes tensor to match the desired shape\n","  # Tile along the first axis (axis=0) num_replications times.  Keep the other dimensions unchanged (1 and 1)\n","  prototypes_tiled = tf.tile(prototypes_expanded, (num_replications, 1, 1))\n","\n","  # 2. Preparing query examples for distance calculation by repeating them across classes.\n","  q_latent_expanded = tf.expand_dims(q_latent, axis=1)\n","  # Calculate queries_tiled, considering the variables q_latent_expanded and num_classes\n","  queries_tiled = tf.tile(q_latent_expanded, (1, num_classes, 1))\n","\n","  # 3. Calculating squared Euclidean distances between each class prototype (prototypes_tiled) and queries (queries_tiled).\n","  distance_squares = tf.square(prototypes_tiled - queries_tiled)\n","  distances = tf.reduce_mean(distance_squares, axis=2)\n","\n","  # 4. TODO: Applying log softmax to negative distances to get log probabilities.\n","  log_softmax = tf.nn.log_softmax(-distances, axis=1)\n","\n","\n","  log_probs = tf.reshape(log_softmax, [num_classes, num_queries, -1])\n","\n","  # 5. Calculating cross-entropy loss\n","  labels_onehot_multiplied = tf.multiply(labels_onehot, log_probs)\n","  summed_labels_onehot = tf.reduce_sum(labels_onehot_multiplied, axis=-1)\n","  ce_loss = -tf.reduce_mean(tf.reduce_sum(log_probs * labels_onehot, axis=[1, 2]))\n","\n","  # 6. Calculating accuracy\n","  predicted_classes = tf.argmax(log_probs, axis=-1)\n","  true_classes = tf.argmax(labels_onehot, axis=-1)\n","  correct_predictions = tf.equal(predicted_classes, true_classes)\n","  accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n","\n","  #############################\n","  return ce_loss, accuracy"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Main run code for the prototypical network. Please complete the code with **TODO** marks"],"metadata":{"id":"tDhiLY1QHWj5"}},{"cell_type":"code","metadata":{"id":"S_bOml4PhkSM","executionInfo":{"status":"ok","timestamp":1707942743706,"user_tz":-60,"elapsed":3,"user":{"displayName":"DANI asensi","userId":"03754562011649161128"}}},"source":["# run_ProtoNet\n","from PIL import Image\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import os\n","import glob\n","import matplotlib.pyplot as plt\n","\n","def proto_net_train_step(model, optim, x, q, labels_ph):\n","  num_classes, num_support, im_height, im_width, channels = x.shape\n","  num_queries = q.shape[1]\n","  x = tf.reshape(x, [-1, im_height, im_width, channels])\n","  q = tf.reshape(q, [-1, im_height, im_width, channels])\n","\n","  with tf.GradientTape() as tape:\n","    x_latent = model(x)\n","    q_latent = model(q)\n","    ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries)\n","\n","  gradients = tape.gradient(ce_loss, model.trainable_variables)\n","  optim.apply_gradients(zip(gradients, model.trainable_variables))\n","  return ce_loss, acc\n","\n","def proto_net_eval(model, x, q, labels_ph):\n","  num_classes, num_support, im_height, im_width, channels = x.shape\n","  num_queries = q.shape[1]\n","  x = tf.reshape(x, [-1, im_height, im_width, channels])\n","  q = tf.reshape(q, [-1, im_height, im_width, channels])\n","\n","  x_latent = model(x)\n","  q_latent = model(q)\n","  ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries)\n","\n","  return ce_loss, acc\n","\n","def run_protonet(data_path='./omniglot_resized', n_way=20, k_shot=1, n_query=5, n_meta_test_way=20, k_meta_test_shot=5, n_meta_test_query=5):\n","  n_epochs = 20\n","  n_episodes = 100\n","\n","  im_width, im_height, channels = 28, 28, 1\n","  num_filters = 32\n","  latent_dim = 16\n","  num_conv_layers = 3\n","  n_meta_test_episodes = 1000\n","\n","  model = ProtoNet([num_filters]*num_conv_layers, latent_dim)\n","  optimizer = tf.keras.optimizers.Adam()\n","\n","    # call DataGenerator with k_shot+n_query samples per class\n","  data_generator = DataGenerator(n_way, k_shot+n_query, n_meta_test_way, k_meta_test_shot+n_meta_test_query)\n","  for ep in range(n_epochs):\n","    for epi in range(n_episodes):\n","      #############################\n","      #### YOUR CODE GOES HERE ####\n","\n","      # sample a batch of validation data and partition it into\n","      # support and query sets\n","      image_batches, label_batches = data_generator.sample_batch('meta_val', 1, shuffle=False)\n","      support = image_batches[:, :, :k_shot, :].reshape(n_way, k_shot, im_height, im_width, channels)\n","      query = image_batches[:, :, k_shot:, :].reshape(n_way, n_query, im_height, im_width, channels)\n","      labels = label_batches[:, :, k_shot:, :].reshape(n_way, n_query, n_way)\n","\n","      #############################\n","      ls, ac = proto_net_train_step(model, optimizer, x=support, q=query, labels_ph=labels)\n","      if (epi+1) % 50 == 0:\n","        #############################\n","        #### YOUR CODE GOES HERE ####\n","\n","        # sample a batch of validation data and partition it into\n","        # support and query sets\n","\n","        image_batches, label_batches = data_generator.sample_batch('meta_val', 1, shuffle=False)\n","        support = image_batches[:, :, :k_shot, :].reshape(n_way, k_shot, im_height, im_width, channels)\n","        # TODO: Calculate query and labels (similarly to support set)\n","        query = image_batches[:, :, k_shot:, :].reshape(n_way, n_query, im_height, im_width, channels)\n","        labels = label_batches[:, :, k_shot:, :].reshape(n_way, n_query, n_way)\n","\n","\n","        #############################\n","        val_ls, val_ac = proto_net_eval(model, x=support, q=query, labels_ph=labels)\n","        print('[epoch {}/{}, episode {}/{}] => meta-training loss: {:.5f}, meta-training acc: {:.5f}, meta-val loss: {:.5f}, meta-val acc: {:.5f}'.format(ep+1,\n","                                                                    n_epochs,\n","                                                                    epi+1,\n","                                                                    n_episodes,\n","                                                                    ls,\n","                                                                    ac,\n","                                                                    val_ls,\n","                                                                    val_ac))\n","\n","  print('Testing...')\n","  meta_test_accuracies = []\n","  for epi in range(n_meta_test_episodes):\n","    #############################\n","    #### YOUR CODE GOES HERE ####\n","\n","    # sample a batch of test data and partition it into\n","    # support and query sets\n","\n","    image_batches, label_batches = data_generator.sample_batch('meta_test', 1, shuffle=False)\n","    support = image_batches[:, :, :k_meta_test_shot, :].reshape(n_meta_test_way, k_meta_test_shot, im_height, im_width, channels)\n","    # TODO: Calculate query and labels (similarly to support set)\n","    query = image_batches[:, :, k_meta_test_shot:, :].reshape(n_meta_test_way, n_meta_test_query, im_height, im_width, channels)\n","    labels = label_batches[:, :, k_meta_test_shot:, :].reshape(n_meta_test_way, n_meta_test_query, n_meta_test_way)\n","\n","\n","    #############################\n","    ls, ac = proto_net_eval(model, x=support, q=query, labels_ph=labels)\n","    meta_test_accuracies.append(ac)\n","    if (epi+1) % 50 == 0:\n","      print('[meta-test episode {}/{}] => loss: {:.5f}, acc: {:.5f}'.format(epi+1, n_meta_test_episodes, ls, ac))\n","  avg_acc = np.mean(meta_test_accuracies)\n","  stds = np.std(meta_test_accuracies)\n","  print('Average Meta-Test Accuracy: {:.5f}, Meta-Test Accuracy Std: {:.5f}'.format(avg_acc, stds))"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["If the code is correct, a meta-val acc=0.20 is obtained during the first epochs. This accuracy should increase after some training epochs."],"metadata":{"id":"DLQxbwN_Jgj3"}},{"cell_type":"code","metadata":{"id":"y6Tv12fbTQqJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1656546-750f-43ef-d18b-4fdc3a4cc569"},"source":["run_protonet('./omniglot_resized/', n_way=5, k_shot=1, n_query=5, n_meta_test_way=5, k_meta_test_shot=4, n_meta_test_query=4)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[epoch 1/20, episode 50/100] => meta-training loss: 8.04719, meta-training acc: 0.20000, meta-val loss: 8.04719, meta-val acc: 0.20000\n","[epoch 1/20, episode 100/100] => meta-training loss: 8.04719, meta-training acc: 0.20000, meta-val loss: 8.04719, meta-val acc: 0.20000\n","[epoch 2/20, episode 50/100] => meta-training loss: 8.04719, meta-training acc: 0.20000, meta-val loss: 8.04719, meta-val acc: 0.64000\n","[epoch 2/20, episode 100/100] => meta-training loss: 8.03967, meta-training acc: 0.52000, meta-val loss: 8.04575, meta-val acc: 0.44000\n","[epoch 3/20, episode 50/100] => meta-training loss: 4.88564, meta-training acc: 0.72000, meta-val loss: 4.90744, meta-val acc: 0.64000\n","[epoch 3/20, episode 100/100] => meta-training loss: 4.24983, meta-training acc: 0.68000, meta-val loss: 6.57624, meta-val acc: 0.40000\n","[epoch 4/20, episode 50/100] => meta-training loss: 4.08805, meta-training acc: 0.72000, meta-val loss: 4.95958, meta-val acc: 0.52000\n","[epoch 4/20, episode 100/100] => meta-training loss: 3.99592, meta-training acc: 0.76000, meta-val loss: 2.74587, meta-val acc: 0.76000\n","[epoch 5/20, episode 50/100] => meta-training loss: 2.85071, meta-training acc: 0.76000, meta-val loss: 6.48108, meta-val acc: 0.36000\n","[epoch 5/20, episode 100/100] => meta-training loss: 7.16340, meta-training acc: 0.36000, meta-val loss: 6.43583, meta-val acc: 0.52000\n","[epoch 6/20, episode 50/100] => meta-training loss: 2.87082, meta-training acc: 0.68000, meta-val loss: 5.76341, meta-val acc: 0.56000\n","[epoch 6/20, episode 100/100] => meta-training loss: 5.31268, meta-training acc: 0.68000, meta-val loss: 5.79940, meta-val acc: 0.48000\n","[epoch 7/20, episode 50/100] => meta-training loss: 2.15588, meta-training acc: 0.84000, meta-val loss: 5.35621, meta-val acc: 0.68000\n","[epoch 7/20, episode 100/100] => meta-training loss: 4.19858, meta-training acc: 0.64000, meta-val loss: 1.80836, meta-val acc: 0.92000\n","[epoch 8/20, episode 50/100] => meta-training loss: 4.76034, meta-training acc: 0.56000, meta-val loss: 3.57075, meta-val acc: 0.68000\n","[epoch 8/20, episode 100/100] => meta-training loss: 7.33626, meta-training acc: 0.64000, meta-val loss: 2.02522, meta-val acc: 0.80000\n","[epoch 9/20, episode 50/100] => meta-training loss: 2.71984, meta-training acc: 0.80000, meta-val loss: 5.03416, meta-val acc: 0.64000\n","[epoch 9/20, episode 100/100] => meta-training loss: 4.65619, meta-training acc: 0.72000, meta-val loss: 5.07545, meta-val acc: 0.52000\n","[epoch 10/20, episode 50/100] => meta-training loss: 2.40623, meta-training acc: 0.88000, meta-val loss: 4.07656, meta-val acc: 0.64000\n","[epoch 10/20, episode 100/100] => meta-training loss: 2.05630, meta-training acc: 0.88000, meta-val loss: 1.86639, meta-val acc: 0.76000\n","[epoch 11/20, episode 50/100] => meta-training loss: 3.56402, meta-training acc: 0.68000, meta-val loss: 5.12178, meta-val acc: 0.48000\n","[epoch 11/20, episode 100/100] => meta-training loss: 3.90658, meta-training acc: 0.80000, meta-val loss: 2.67014, meta-val acc: 0.80000\n","[epoch 12/20, episode 50/100] => meta-training loss: 3.55522, meta-training acc: 0.60000, meta-val loss: 3.27669, meta-val acc: 0.72000\n","[epoch 12/20, episode 100/100] => meta-training loss: 7.36752, meta-training acc: 0.48000, meta-val loss: 4.95185, meta-val acc: 0.72000\n","[epoch 13/20, episode 50/100] => meta-training loss: 3.64608, meta-training acc: 0.72000, meta-val loss: 4.28442, meta-val acc: 0.72000\n","[epoch 13/20, episode 100/100] => meta-training loss: 2.40355, meta-training acc: 0.72000, meta-val loss: 4.17606, meta-val acc: 0.80000\n","[epoch 14/20, episode 50/100] => meta-training loss: 2.54995, meta-training acc: 0.80000, meta-val loss: 3.54905, meta-val acc: 0.68000\n","[epoch 14/20, episode 100/100] => meta-training loss: 1.55687, meta-training acc: 0.84000, meta-val loss: 1.69854, meta-val acc: 0.80000\n","[epoch 15/20, episode 50/100] => meta-training loss: 1.46245, meta-training acc: 0.96000, meta-val loss: 3.73761, meta-val acc: 0.72000\n","[epoch 15/20, episode 100/100] => meta-training loss: 3.17866, meta-training acc: 0.88000, meta-val loss: 2.26383, meta-val acc: 0.80000\n","[epoch 16/20, episode 50/100] => meta-training loss: 3.62046, meta-training acc: 0.76000, meta-val loss: 2.59048, meta-val acc: 0.88000\n","[epoch 16/20, episode 100/100] => meta-training loss: 1.16186, meta-training acc: 0.92000, meta-val loss: 2.00958, meta-val acc: 0.96000\n","[epoch 17/20, episode 50/100] => meta-training loss: 1.85533, meta-training acc: 0.96000, meta-val loss: 2.99951, meta-val acc: 0.84000\n","[epoch 17/20, episode 100/100] => meta-training loss: 3.74869, meta-training acc: 0.80000, meta-val loss: 2.49737, meta-val acc: 0.84000\n","[epoch 18/20, episode 50/100] => meta-training loss: 3.18005, meta-training acc: 0.84000, meta-val loss: 6.49465, meta-val acc: 0.36000\n","[epoch 18/20, episode 100/100] => meta-training loss: 1.02430, meta-training acc: 0.96000, meta-val loss: 1.67730, meta-val acc: 0.88000\n","[epoch 19/20, episode 50/100] => meta-training loss: 1.29337, meta-training acc: 0.88000, meta-val loss: 3.99895, meta-val acc: 0.60000\n","[epoch 19/20, episode 100/100] => meta-training loss: 4.13443, meta-training acc: 0.76000, meta-val loss: 2.18378, meta-val acc: 0.80000\n","[epoch 20/20, episode 50/100] => meta-training loss: 1.84659, meta-training acc: 0.96000, meta-val loss: 1.69784, meta-val acc: 0.96000\n","[epoch 20/20, episode 100/100] => meta-training loss: 5.43846, meta-training acc: 0.60000, meta-val loss: 7.16080, meta-val acc: 0.44000\n","Testing...\n","[meta-test episode 50/1000] => loss: 3.11282, acc: 0.90000\n","[meta-test episode 100/1000] => loss: 1.73743, acc: 0.80000\n","[meta-test episode 150/1000] => loss: 2.49922, acc: 0.85000\n","[meta-test episode 200/1000] => loss: 2.74202, acc: 0.75000\n","[meta-test episode 250/1000] => loss: 1.62961, acc: 0.95000\n","[meta-test episode 300/1000] => loss: 2.34430, acc: 0.75000\n","[meta-test episode 350/1000] => loss: 2.32605, acc: 0.85000\n","[meta-test episode 400/1000] => loss: 1.45011, acc: 0.90000\n","[meta-test episode 450/1000] => loss: 3.73158, acc: 0.85000\n","[meta-test episode 500/1000] => loss: 1.48993, acc: 0.95000\n","[meta-test episode 550/1000] => loss: 1.16549, acc: 0.85000\n","[meta-test episode 600/1000] => loss: 0.61834, acc: 1.00000\n","[meta-test episode 650/1000] => loss: 2.15835, acc: 0.75000\n","[meta-test episode 700/1000] => loss: 2.50302, acc: 0.85000\n","[meta-test episode 750/1000] => loss: 0.92423, acc: 0.90000\n"]}]}]}