{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPSaU-uRo0Dm"
   },
   "source": [
    "# **TAREA 1a: Graph Neural Networks (Teoría y ejemplos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcwprQJBo0Dr"
   },
   "source": [
    "En esta tarea trataremos la aplicación de redes neuronales en grafos. Las Graph Neural Networks (GNNs) han crecido en popularidad tanto en aplicaciones como en investigación, incluyendo campos como redes sociales, knowledge graphs, sistemas de recomendación y bioinformática. Aunque la teoría y las matemáticas que subyacen a las GNN pueden parecer complicadas en un principio, la implementación de estos modelos es bastante sencilla y ayuda a comprender la metodología. Por lo tanto, analizaremos la implementación de las capas básicas de una GNN, que son las graph convolutions y las attention layers. Por último, aplicaremos una GNN a tareas a nivel de nodo, de arista y de grafo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47lWcbP8o0Dr",
    "outputId": "84c5645d-b0dc-4cbd-a313-fb052e95ca98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/bg12rs4d7n3c6p64vwtqhqqh0000gn/T/ipykernel_14842/3732865111.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # Para exportarlo\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "## Librerias\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # Para exportarlo\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "## Barra de progreso\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10 #dataset de imágenes de 10 clases diferentes\n",
    "from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError:\n",
    "    !pip install --quiet pytorch-lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Path donde cargar/guardar los datasets\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path donde guardar los modelos pre-entrenados\n",
    "CHECKPOINT_PATH = \"../saved_models/tarea1\"\n",
    "\n",
    "# Semilla\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Poner las operaciones deterministicas en la GPU para poder reproducirlas\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Configuración de dispositivo \n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvRpp9u2o0Du"
   },
   "source": [
    "Antes de seguir, se deben incluir en la carpeta \"tarea1\" los tres ficheros siguientes: \"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\" y \"GraphLevelGraphConv.ckpt\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-7NLdD4o0Dv"
   },
   "source": [
    "## Un poquito de teoría de Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpjjFeYko0Dv"
   },
   "source": [
    "### ¿Cómo representar un grafo?\n",
    "\n",
    "Antes de nada, vamos a definir como se representa un grafo. Matemáticamente, un grafo $\\mathcal{G}$ se define como una tupla de un conjunto de nodos $V$, y un conjunto de aristas $E$: $\\mathcal{G}=(V,E)$. Cada arista se representa como un par de valores (nodos), y representan una conexión entre ellos.\n",
    "Los aristas pueden tener pesos o no (weighted o unweighted) y tener dirección o no (directed o undirected).\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "<center width=\"100%\" style=\"padding:10px\"><img src=\"https://uvadlc-notebooks.readthedocs.io/en/latest/_images/example_graph.svg\" width=\"250px\"></center>\n",
    "\n",
    "Los nodos son $V=\\{1,2,3,4\\}$, y las aristas $E=\\{(1,2), (2,3), (3,4), (2,4)\\}$. Por simplicidad, es unweighted y undirected, y deberían incluirse los pares simétricos (por ejemplo, el $(2,1)$). Normalmente, para las aristas, se usa para representar los valores y operar con ellas la matriz de adyacencia o la lista de pares de nodos .\n",
    "\n",
    "La **Matriz de Adyacencia** $A$ es una matriz cuadrada cuyos elementos indican todos los pares denodos que son adyacentes, es decir, conectados o no. En el caso más simple, $A_{ij}$ = 1 si hay conexión entre los nodos $i$ y $j$, y 0 en el caso de que no haya conexión. Si los aristas tuviesen peso, ese valor sustituiría a los unos. Un grafo no dirigido es simétrico, y por lo tanto ($A_{ij}=A_{ji}$). Para el ejemplo, tenemos la matriz de adyacencia siguiente:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "    0 & 1 & 0 & 0\\\\\n",
    "    1 & 0 & 1 & 1\\\\\n",
    "    0 & 1 & 0 & 1\\\\\n",
    "    0 & 1 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "En esta tarea usaremos la matriz de adyacencia para que se vea más simple y claro visualmente, pero en terminos de eficiencia de memoria es mejor las listas de aristas (y las librerías suelen implementarlas más).\n",
    "Se puede pasar de listas a matrices dispersas (sparse), haciendolo eficiente, mediante el subpaquete`torch.sparse` ([documentación](https://pytorch.org/docs/stable/sparse.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb2ezWRGo0Dv"
   },
   "source": [
    "### Convoluciones de grafos (Graph Convolutions, GCNs)\n",
    "\n",
    "Las GCNs, introducidas por [Kipf et al.](https://openreview.net/pdf?id=SJU4ayYgl) in 2016 [blog](https://tkipf.github.io/graph-convolutional-networks/), son parecidas a las convoluciones en imágenes en el sentido de filtrado de parámetros compartido en diferentes localizaciones del grafo. Al mismo tiempo, se basan en métodos de paso de mensajes, lo que significa que los nodos intercambian información con los vecinos y se envían \"mensajes\" entre sí. Antes de ver la notación matemática, podemos intentar comprender visualmente cómo funcionan las GCN.\n",
    "En un primer paso, cada nodo crea un vector de características que representa el mensaje que quiere enviar a todos sus vecinos. En el segundo paso, los mensajes se envían a los vecinos, de forma que un nodo recibe un mensaje por nodo adyacente o vecino. A continuación se muestran ambos pasos con el ejemplo anterior :\n",
    "\n",
    "<center width=\"100%\" style=\"padding:10px\"><img src=\"https://miro.medium.com/v2/resize:fit:1246/0*zhmuVMqj8pgvJI3O\" width=\"700px\"></center>\n",
    "\n",
    "Si queremos formularlo en términos más matemáticos, primero tenemos que decidir cómo combinar todos los mensajes que recibe un nodo. Como el número de mensajes varía de un nodo a otro, necesitamos una operación que funcione para cualquier número. Por eso, lo habitual es la suma o la media. Dadas las características anteriores de los nodos $H^{(l)}$, la capa GCN se define como:\n",
    "\n",
    "$$H^{(l+1)} = \\sigma\\left(\\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}H^{(l)}W^{(l)}\\right)$$\n",
    "\n",
    "$W^{(l)}$ son los pesos de los parámetros con los que transformamos las características de entrada en mensajes ($H^{(l)}W^{(l)}$). A la matriz de adyacencia $A$ le añadimos la matriz identidad para que cada nodo se envíe su propio mensaje también a sí mismo, representándolo así: $\\hat{A}=A+I$. Por último, para sacar la media en este caso, calculamos la matriz $\\hat{D}$ que es una matriz diagonal donde $D_{ii}$ contiene el número de vecinos que tiene el nodo $i$. Por último, $\\sigma$ representa una función de activación arbitraria, y no necesariamente la sigmoidea (normalmente en las GNNs se utiliza una función de activación basada en ReLU).\n",
    "\n",
    "Al implementar la capa GCN en PyTorch, podemos aprovechar la flexibilidad de las operaciones sobre tensores. En lugar de definir una matriz $\\hat{D}$, podemos simplemente dividir los mensajes sumados por el número de vecinos después. Además, sustituimos la matriz de pesos por una capa lineal, que adicionalmente nos permite añadir un sesgo.\n",
    "El código de la capa GCN se debe definir de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VX3f8Vq6o0Dw"
   },
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "\n",
    "    #Entradas \n",
    "    #c_in: Número de características (channels) de entrada.\n",
    "    #c_out: Número de características (channels) de salida.\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "\n",
    "    #Esta función realiza la propagación hacia adelante (forward pass) de la capa GCN.\n",
    "    def forward(self, node_feats, adj_matrix):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            node_feats - Tensor con las características del nodo con formato [batch_size, num_nodes, c_in].\n",
    "            adj_matrix - Matriz de adyacencia del grafo. Si hay una arista del nodo i al j, adj_matrix[b,i,j]=1 sino 0.\n",
    "                         También admite grafos dirigidos, asumiendo que ya llevan la matriz identidad sumada en batch_size: [batch_size, num_nodes, num_nodes]\n",
    "        \"\"\"\n",
    "        #Numero de vecinos (num_neighbours), en este caso, se refiere a los vecinos de entrada (in) en grafos dirigidos\n",
    "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
    "        #Proyecta las características de los nodos de c_in a c_out \n",
    "        node_feats = self.projection(node_feats)\n",
    "        #Realiza una multiplicación de matrices en batch entre la matriz de adyacencia y las características de los nodos proyectadas. Esto efectivamente suma las características de los vecinos de cada nodo.\n",
    "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
    "        #Normalización de las caracteristicas \n",
    "        node_feats = node_feats / num_neighbours\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6dKxbRgo0Dw"
   },
   "source": [
    "Para comprender mejor la capa GCN, lo podemos aplicar a nuestro grafo de ejemplo anterior. En primer lugar, especifiquemos algunas características de los nodos y la matriz de adyacencia con autoconexiones añadidas (self-loops):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D30KHuf6o0Dw",
    "outputId": "cb4ebab4-539b-4775-b9e9-2174410110e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características de los nodos:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\\Matriz de adyacencia:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "#Crea un tensor unidimensional con valores [0., 1., 2., 3., 4., 5., 6., 7.] de tipo float32.\n",
    "# .view(1, 4, 2): Cambia la forma (shape) del tensor a un tensor tridimensional. El tensor resultante tiene una forma de [1, 4, 2], lo que significa 1 batch, 4 nodos, y 2 características por nodo.\n",
    "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "\n",
    "# Creando un tensor tridimensional que representa una matriz de adyacencia para un grafo dirigido con 4 nodos\n",
    "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
    "                            [1, 1, 1, 1],\n",
    "                            [0, 1, 1, 1],\n",
    "                            [0, 1, 1, 1]]])\n",
    "\n",
    "print(\"Características de los nodos:\\n\", node_feats)\n",
    "print(\"\\Matriz de adyacencia:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeF2nuN3o0Dx"
   },
   "source": [
    "A continuación, vamos a aplicarle una capa GCN. Para simplificar, inicializamos la matriz de pesos lineal como una matriz de identidad para que las características de entrada sean iguales a los mensajes. Esto nos facilita la verificación de la operación de paso de mensajes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uqu9h_po0Dx",
    "outputId": "2c0a7329-f0ef-4add-ecca-ac88686f61f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de adyacencia tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Características de entrada tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Características de salida tensor([[[1., 2.],\n",
      "         [3., 4.],\n",
      "         [4., 5.],\n",
      "         [4., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "# Creamos una capa 2 características de entrada y 2 de salida.\n",
    "layer = GCNLayer(c_in=2, c_out=2)\n",
    "\n",
    "# Configurando manualmente los pesos y el sesgo de la capa lineal, no cambiará las características de entrada.\n",
    "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
    "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
    "\n",
    "# Aplicación de la capa\n",
    "with torch.no_grad(): #Dentro de este bloque de código incluimos todo lo que queremos ejecutar sin cálculo de gradientes para no hacer backpropagation\n",
    "    out_feats = layer(node_feats, adj_matrix)\n",
    "\n",
    "print(\"Matriz de adyacencia\", adj_matrix)\n",
    "print(\"Características de entrada\", node_feats)\n",
    "print(\"Características de salida\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdxoQTA8o0Dx"
   },
   "source": [
    "Como podemos ver, los valores de salida del primer nodo son la media de sí mismo y del segundo nodo. Del mismo modo, podemos verificar todos los demás nodos. Sin embargo, en una GNN, también querríamos permitir el intercambio de características entre nodos más allá de sus vecinos. Esto se puede conseguir aplicando múltiples capas GCN, lo que nos da la disposición final de una GNN. La GNN puede construirse mediante una secuencia de capas GCN y no lineales como ReLU. Se puede ver en la imagen.\n",
    "\n",
    "<center width=\"100%\" style=\"padding: 10px\"><img src=\"https://theaisummer.com/static/cb743cf6762bf14d48c1548bf0f0fe1f/9a128/gnn.jpg\" width=\"600px\"></center>\n",
    "\n",
    "Sin embargo, un problema que podemos ver al observar el ejemplo anterior es que las características de salida de los nodos 3 y 4 son las mismas porque tienen los mismos nodos adyacentes (incluido él mismo). Por lo tanto, las capas GCN pueden hacer que la red olvide la información específica de cada nodo si sólo tomamos la media de todos los mensajes. Se han propuesto muchas mejoras posibles. Mientras que la opción más sencilla podría ser utilizar conexiones residuales, el enfoque más común es ponderar más las autoconexiones o definir una matriz de pesos separada para las autoconexiones. Alternativamente, podemos tratarlo con Graph Attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_cagrRUo0Dy"
   },
   "source": [
    "### Graph Attention\n",
    "\n",
    "Antes de nada, tenemos que explicar **¿Qué es la atención?** Se trata de un mecanismo de capas de redes neuronales basada en secuenciación. Se puede definir como una media ponderada de elementos de secuencia con los pesos calculados de forma dinámica en función de una consulta de entrada y elementos clave.\n",
    "El objetivo es hacer una media de las características de varios elementos. Sin embargo, en lugar de ponderar cada elemento por igual, queremos ponderarlos en función de sus valores reales. En otras palabras, queremos decidir dinámicamente a qué entradas queremos \"prestar más atención\" que a otras. Se organiza en cuatro partes:\n",
    "\n",
    "\n",
    "*   Consulta (query):  vector de características que describe lo que estamos buscando en la secuencia, es decir, a qué querríamos prestar atención.\n",
    "*   Claves (keys): para cada elemento de entrada, tenemos una clave que, de nuevo, es un vector de características. Este vector de características describe a grandes rasgos lo que el elemento \"ofrece\", o cuándo puede ser importante. Las claves deben diseñarse de forma que podamos identificar los elementos a los que queremos prestar atención basándonos en la consulta.\n",
    "*   Valores (values): para cada elemento de entrada, también tenemos un vector de valores. Este vector de características es el que queremos promediar.\n",
    "*   Función de puntuación (score function): para calificar los elementos a los que queremos prestar atención, necesitamos especificar una función de puntuación, la cual toma como entrada la consulta y una clave, y da como salida la puntuación/peso de atención del par consulta-clave. Suele implementarse mediante métricas de similitud sencillas.\n",
    "\n",
    "Los pesos de la media se calculan mediante un softmax sobre todas las salidas de la función de puntuación. Por lo tanto, asignamos un peso mayor a aquellos vectores de valores cuya clave correspondiente es más similar a la consulta.\n",
    "\n",
    "\n",
    "**¿Y si aplicamos este concepto a los grafos? ** Puede aplicarse de forma similar a los grafos, con las Graph Attention Network (GAT). De forma similar a la GCN, la capa de atención de grafos crea un mensaje para cada nodo utilizando una matriz lineal de capa/peso. Para la parte de atención, utiliza el mensaje del propio nodo como consulta, y los mensajes a promediar como claves y valores (nótese que esto también incluye el mensaje a sí mismo). La función de puntuación $f_{atcn}$ se implementa como un Multi-Layer Perceptron (MLP) de una capa que asigna la consulta y la clave a un único valor. El MLP tiene el siguiente aspecto:\n",
    "\n",
    "\n",
    "<center width=\"100%\" style=\"padding:10px\"><img src=\"https://pctg.net/wp-content/uploads/2023/07/1688971037_411_Todo-lo-que-necesitas-saber-sobre-Graph-Attention-Networks.png\" width=\"250px\"></center>\n",
    "\n",
    "Entremos con un poco de notación matemática:\n",
    "\n",
    "$h_i$ y $h_j$ son las característias originales de los nodos $i$ y $j$ respectivamente, y representa los mensajes de la capa con $\\mathbf{W}$ como matriz de pesos. $\\mathbf{a}$ es la matriz de pesos de la MLP, la cual tiene la forma $[1,2\\times d_{\\text{msg}}]$, y $\\alpha_{ij}$ el peso de atención final desde el nodo $i$ al $j$. El cálculo puede ser descrito mediante la siguiente fórmula:\n",
    "\n",
    "$$\\alpha_{ij} = \\frac{\\exp\\left(\\text{LeakyReLU}\\left(\\mathbf{a}\\left[\\mathbf{W}h_i||\\mathbf{W}h_j\\right]\\right)\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\text{LeakyReLU}\\left(\\mathbf{a}\\left[\\mathbf{W}h_i||\\mathbf{W}h_k\\right]\\right)\\right)}$$\n",
    "\n",
    "El operador $||$ representa la concatenación, y $\\mathcal{N}_i$ los índices de los vecinos del nodo $i$. Nótese que, a diferencia de la práctica habitual, aplicamos una no linealidad (LeakyReLU) antes del softmax sobre los elementos.Aunque a primera vista parece un cambio menor, es crucial para que la atención dependa de la entrada original. Vamos a eliminar la no linealidad por un momento, y tratar de simplificar la expresión:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\alpha_{ij} & = \\frac{\\exp\\left(\\mathbf{a}\\left[\\mathbf{W}h_i||\\mathbf{W}h_j\\right]\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\mathbf{a}\\left[\\mathbf{W}h_i||\\mathbf{W}h_k\\right]\\right)}\\\\[5pt]\n",
    "    & = \\frac{\\exp\\left(\\mathbf{a}_{:,:d/2}\\mathbf{W}h_i+\\mathbf{a}_{:,d/2:}\\mathbf{W}h_j\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\mathbf{a}_{:,:d/2}\\mathbf{W}h_i+\\mathbf{a}_{:,d/2:}\\mathbf{W}h_k\\right)}\\\\[5pt]\n",
    "    & = \\frac{\\exp\\left(\\mathbf{a}_{:,:d/2}\\mathbf{W}h_i\\right)\\cdot\\exp\\left(\\mathbf{a}_{:,d/2:}\\mathbf{W}h_j\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\mathbf{a}_{:,:d/2}\\mathbf{W}h_i\\right)\\cdot\\exp\\left(\\mathbf{a}_{:,d/2:}\\mathbf{W}h_k\\right)}\\\\[5pt]\n",
    "    & = \\frac{\\exp\\left(\\mathbf{a}_{:,d/2:}\\mathbf{W}h_j\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\mathbf{a}_{:,d/2:}\\mathbf{W}h_k\\right)}\\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "\n",
    "Podemos ver que sin la no linealidad, el término de atención con $h_i$ en realidad se anula a sí mismo, por lo que la atención es independiente del propio nodo. Por lo tanto, tendríamos el mismo problema que el GCN de crear las mismas características de salida para los nodos con los mismos vecinos. Por eso el LeakyReLU es crucial y añade cierta dependencia de $h_i$ a la atención.\n",
    "\n",
    "Una vez que obtenemos todos los factores de atención, podemos calcular las características de salida para cada nodo realizando la media ponderada:\n",
    "\n",
    "$$h_i'=\\sigma\\left(\\sum_{j\\in\\mathcal{N}_i}\\alpha_{ij}\\mathbf{W}h_j\\right)$$\n",
    "\n",
    "$\\sigma$ es aún no lineal, como una capa GCN. Visualmente, podríamos representar el paso completo del mensaje en una capa de atención.\n",
    "\n",
    "<center width=\"100%\"><img src=\"https://mila.quebec/wp-content/uploads/2018/07/687474703a2f2f7777772e636c2e63616d2e61632e756b2f25374570763237332f696d616765732f6761742e6a7067-1024x669.jpeg\" width=\"400px\"></center>\n",
    "\n",
    "Para aumentar la expresividad de la red de atención gráfica propusieron ampliarla a múltiples cabezas, con $N$ capas de atención que se aplican en paralelo. En la imagen de arriba, se visualiza como tres colores diferentes de flechas (verde, azul y morado) se concatenan. La media sólo se aplica a la última capa de predicción de una red.\n",
    "\n",
    "Un ejemplo de implementación sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TeZa7Oqio0Dy"
   },
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    #c_in: Número de características de entrada.\n",
    "    #c_out: Número de características de salida.\n",
    "    #num_heads: Número de \"cabezas\" de atención. Cada \"cabeza\" aprende diferentes pesos de atención y, por lo tanto, puede atender a diferentes partes de la información de entrada.\n",
    "    #concat_heads: Si es True, concatena las salidas de las diferentes cabezas.\n",
    "    #alpha: Pendiente negativa de la activación LeakyReLU.\n",
    "    def __init__(self, c_in, c_out, num_heads=1, concat_heads=True, alpha=0.2):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimensionalidad de las características de entrada\n",
    "            c_out - Dimensionalidad de las características de salida\n",
    "            num_heads - Número de heads (para trabajar en paralelo). Las características de salida se reparten equitativamente por cada head si concat_heads=True.\n",
    "            concat_heads - Si es True, la salida de cada head se concatena en lugar de promediarse.\n",
    "            alpha - Pendiente negativa de la activación LeakyReLU.\n",
    "        \"\"\"\n",
    "        super().__init__() #Inicializamos\n",
    "        self.num_heads = num_heads\n",
    "        self.concat_heads = concat_heads\n",
    "        if self.concat_heads:\n",
    "            assert c_out % num_heads == 0, \"El número de características de salida debe ser múltiplo del número de heads.\"\n",
    "            c_out = c_out // num_heads\n",
    "\n",
    "        # Sub-modulos y parámetros necesarios en la capa\n",
    "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
    "        self.a = nn.Parameter(torch.Tensor(num_heads, 2 * c_out)) # Uno por head\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "        # Inicialización de la implementación original\n",
    "        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix, print_attn_probs=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            node_feats - Características de entrada del nodo. Formato: [batch_size, c_in]\n",
    "            adj_matrix - Matriz de adyacencia con self-loops. Formato: [batch_size, num_nodes, num_nodes]\n",
    "            print_attn_probs - Si es True, los pesos de atención se muestran durante el paso forward (debugging)\n",
    "        \"\"\"\n",
    "        batch_size, num_nodes = node_feats.size(0), node_feats.size(1) #Se extraen datos del tensor de entrada\n",
    "\n",
    "        # Applicamos una capa lineal y ordenamos los nodos por head\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "\n",
    "        # Tenemos que calcular los \"attention logits\" (valores de la capa de salida, previa a la función de activación) para cada arista de la matriz de adyacencia\n",
    "        # Se trata de algo muy costoso, puesto que hay que hacerlo para toda combinación posible\n",
    "        # Solución => Creamos un tensor [W*h_i||W*h_j] con i y j como índices de todas las aristas\n",
    "        edges = adj_matrix.nonzero(as_tuple=False) # Obtenemos los índices donde la matriz de adyacencia no es 0 (existencia de arista)\n",
    "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
    "        edge_indices_row = edges[:,0] * num_nodes + edges[:,1]\n",
    "        edge_indices_col = edges[:,0] * num_nodes + edges[:,2]\n",
    "        a_input = torch.cat([\n",
    "            torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n",
    "            torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0)\n",
    "        ], dim=-1) # Devuelve un tensor con node_feats_flat con las posiciones indexadas en dim=0\n",
    "\n",
    "        # Calculamos la salida de atención de la MLP (independiente para cada head)\n",
    "        attn_logits = torch.einsum('bhc,hc->bh', a_input, self.a)\n",
    "        attn_logits = self.leakyrelu(attn_logits)\n",
    "\n",
    "        # Se mapea la lista de valores de atención a una matriz de nuevo\n",
    "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape+(self.num_heads,)).fill_(-9e15)\n",
    "        attn_matrix[adj_matrix[...,None].repeat(1,1,1,self.num_heads) == 1] = attn_logits.reshape(-1)\n",
    "\n",
    "        # Se calcula la media de pesos de atención\n",
    "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
    "        if print_attn_probs:\n",
    "            print(\"Probabilidades de atención\\n\", attn_probs.permute(0, 3, 1, 2))\n",
    "        node_feats = torch.einsum('bijh,bjhc->bihc', attn_probs, node_feats)\n",
    "\n",
    "        # Si se desean concatenar los head, se hace un reshaping. En caso contrario tomamos la media\n",
    "        if self.concat_heads:\n",
    "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
    "        else:\n",
    "            node_feats = node_feats.mean(dim=2)\n",
    "\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npNXzrh1o0Dz"
   },
   "source": [
    "Una vez más, podemos aplicar la capa graph attention en nuestro grafo de ejemplo anterior para entender mejor la dinámica. Al igual que antes, la capa de entrada se inicializa como una matriz de identidad, pero ponemos $\\mathbf{a}$ como vector de números arbitrarios para obtener diferentes valores de atención. Utilizamos dos head para mostrar los mecanismos de atención, paralelos e independientes, que trabajan en la capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2kXc6Xlo0Dz",
    "outputId": "797e7112-50d4-4f31-f41f-9a82f3813c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades de atención\n",
      " tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],\n",
      "          [0.1096, 0.1450, 0.2642, 0.4813],\n",
      "          [0.0000, 0.1858, 0.2885, 0.5257],\n",
      "          [0.0000, 0.2391, 0.2696, 0.4913]],\n",
      "\n",
      "         [[0.5100, 0.4900, 0.0000, 0.0000],\n",
      "          [0.2975, 0.2436, 0.2340, 0.2249],\n",
      "          [0.0000, 0.3838, 0.3142, 0.3019],\n",
      "          [0.0000, 0.4018, 0.3289, 0.2693]]]])\n",
      "Matriz de Adyacencia tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Características de entrada tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Características de salida tensor([[[1.2913, 1.9800],\n",
      "         [4.2344, 3.7725],\n",
      "         [4.6798, 4.8362],\n",
      "         [4.5043, 4.7351]]])\n"
     ]
    }
   ],
   "source": [
    "layer = GATLayer(2, 2, num_heads=2) #Dos dimensiones de entrada y salida, y dos head\n",
    "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]]) #Los pesos es la matriz de identidad\n",
    "layer.projection.bias.data = torch.Tensor([0., 0.]) #Sin sesgo\n",
    "layer.a.data = torch.Tensor([[-0.2, 0.3], [0.1, -0.1]]) #Datos de ejemplo\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n",
    "\n",
    "print(\"Matriz de Adyacencia\", adj_matrix)\n",
    "print(\"Características de entrada\", node_feats)\n",
    "print(\"Características de salida\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkhAgHI9o0Dz"
   },
   "source": [
    "Recomendación: intentar calcular la matriz de atención al menos para una cabeza y un nodo por sí mismo. Las entradas son 0 cuando no existe ninguna arista entre $i$ y $j$. Para los demás, vemos un conjunto diverso de probabilidades de atención. Además, las características de salida de los nodos 3 y 4 son ahora diferentes aunque tengan los mismos vecinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYti9Rc1o0D0"
   },
   "source": [
    "## PyTorch Geometric (Grandes grafos)\n",
    "\n",
    "Hemos probado con grafos de ejemplo, pero...**¿Qué ocurre con grafos del mundo real?** Ya hemos mencionado antes que la implementación de grafos con matrices de adyacencia es sencilla y directa, pero puede resultar costosa desde el punto de vista computacional para grafos de gran tamaño. Muchos grafos del mundo real pueden llegar a tener más de cientos de miles o millones nodos (por ejemplo, una red social), por lo que las implementaciones basadas en matrices de adyacencia fallan. Hay muchas optimizaciones posibles al implementar GNNs, y por suerte, existen paquetes que proporcionan dichas capas. Los paquetes más populares para PyTorch son [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) y [Deep Graph Library](https://www.dgl.ai/) (esta última no está específicamente diseñado para funcionar con un framework o entorno de desarrollo particular). Cuál usar depende del proyecto que estemos planeando hacer. Lo primero que vamos a hacer es instalarlo (PyTorch Geometric no está instalado por defecto en GoogleColab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLdzlvtuo0D0"
   },
   "outputs": [],
   "source": [
    "# torch geometric\n",
    "try:\n",
    "    import torch_geometric\n",
    "except ModuleNotFoundError:\n",
    "    # Instalar paquetes torch geometriccon una versión específica de CUDA+PyTorch.\n",
    "    # Más detalles en https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
    "    TORCH = torch.__version__.split('+')[0]\n",
    "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
    "\n",
    "    !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "    !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "    !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "    !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "    !pip install torch-geometric\n",
    "    import torch_geometric\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5fFQndRo0D0"
   },
   "source": [
    "PyTorch Geometric nos proporciona un conjunto de capas de grafos comunes, incluyendo las capas GCN y GAT implementadas antes. Además, de forma similar a torchvision de PyTorch, proporciona los conjuntos de datos de grafos comunes y las transformaciones en ellos para simplificar el entrenamiento. En comparación con nuestra implementación anterior, PyTorch Geometric utiliza una lista de pares de índices para representar las aristas. Los detalles de esta biblioteca se explorarán más a fondo en nuestros experimentos.\n",
    "\n",
    "En nuestras tareas a continuación, queremos que nos permita elegir entre una multitud de capas de grafos. Por lo tanto, definimos de nuevo a continuación un diccionario para acceder usando strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bSV1AW5to0D1"
   },
   "outputs": [],
   "source": [
    "gnn_layer_by_name = {\n",
    "    \"GCN\": geom_nn.GCNConv,\n",
    "    \"GAT\": geom_nn.GATConv,\n",
    "    \"GraphConv\": geom_nn.GraphConv\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geRDbAc8o0D1"
   },
   "source": [
    "Además de las GCN y GAT explicadas, hemos includo la capa `geom_nn.GraphConv` ([documentación](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GraphConv)). GraphConv es un GCN con una matriz de pesos separada para las autoconexiones. Matemáticamente sería así:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i^{(l+1)} = \\mathbf{W}^{(l + 1)}_1 \\mathbf{x}_i^{(l)} + \\mathbf{W}^{(\\ell + 1)}_2 \\sum_{j \\in \\mathcal{N}_i} \\mathbf{x}_j^{(l)}\n",
    "$$\n",
    "\n",
    "En esta fórmula, los mensajes de los vecinos se suman en lugar de promediarse. Sin embargo, PyTorch Geometric proporciona el argumento `aggr` para cambiar entre sumar, promediar y max pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mt9dcea1hW2"
   },
   "source": [
    "# **TAREA 1b: Graph Neural Networks (Práctica)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWQ8Ag6wo0D1"
   },
   "source": [
    "## Experimentos con datos estructurados en grafos\n",
    "\n",
    "Las tareas sobre datos estructurados en grafos pueden agruparse en tres grupos: a nivel de nodo, a nivel de arista y a nivel de grafo. Los distintos niveles describen en qué nivel queremos realizar la clasificación/regresión. A continuación analizaremos los tres tipos con ejemplos concretos, con más detalle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml1-ga1Oo0D1"
   },
   "source": [
    "### A nivel de nodo (Node-level tasks). Ejemplo: clasificación semisupervisada de publicaciones científicas.\n",
    "\n",
    "\n",
    "Las tareas a nivel de nodo tienen como objetivo clasificar los nodos de un grafo. Normalmente, tenemos un único grafo de gran tamaño con más de 1.000 nodos, de los cuales una cierta cantidad están etiquetados. Aprendemos a clasificar esos ejemplos etiquetados durante el entrenamiento e intentamos generalizar a los nodos no etiquetados.\n",
    "\n",
    "Un ejemplo típico es el dataset  [Cora](https://relational.fit.cvut.cz/dataset/CORA), que se trata de una red de citas entre artículos científicos. Cora consta de 2708 publicaciones científicas con 5429 enlaces entre sí que representan la citación de un artículo por otro. La tarea consiste en clasificar cada publicación en una de las siete clases o categorías (Case_Based, Genetic_Algorithms, Neural_Networks, Probabilistic_Methods, Reinforcement_Learning, Rule_Learning y Theory).\n",
    "\n",
    "<center width=\"100%\" style=\"padding:10px\"><img src=\"https://production-media.paperswithcode.com/datasets/Cora-0000000700-ce1c5ec7_LD7pZnT.jpg\" width=\"350px\"></center>\n",
    "\n",
    "\n",
    "Cada publicación está representada por un vector bag-of-words. Esto significa que tenemos un vector de 1433 elementos para cada publicación, donde un 1 en la característica $i$ indica que la $i$-ésima palabra de un diccionario predefinido está en el artículo. Las representaciones binarias de bag-of-words se suelen utilizar cuando necesitamos codificaciones muy sencillas y ya tenemos una intuición de qué palabras esperar en una red. Existen otros enfoques mejores, que se verán más adelante.\n",
    "\n",
    "A continuación cargaremos el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3maF58aVo0D2"
   },
   "outputs": [],
   "source": [
    "cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ-_zmIRo0D2"
   },
   "source": [
    "Vamos a ver cómo PyTorch Geometric representa los datos de grafo. Hay que tener en cuenta que, a pesar de que tenemos un solo grafo, PyTorch Geometric devuelve un conjunto de datos para la compatible con otros datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TgFy7Ok3o0D2",
    "outputId": "330ec467-fd17-4a4e-d736-3a3348069a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10556"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cora_dataset[0]\n",
    "data # x es una matriz de características con formato [num_nodes, num_node_features]\n",
    "#data.is_directed()\n",
    "print(data)\n",
    "data.num_edges # ¿Por qué sale este número de aristas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvUysNDUo0D3"
   },
   "source": [
    "El grafo está representado por un objeto `Data` ([documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)) al que podemos acceder como un namespace estándar de Python. El tensor de índices de aristas es la lista de aristas del grafo y contiene la versión simétrica de cada arista para grafos no dirigidos. Las máscaras `train_mask`, `val_mask` y `test_mask` son máscaras booleanas que indican qué nodos debemos utilizar para el entrenamiento, la validación y la prueba. El tensor `x` es el tensor de características de nuestras 2708 publicaciones, y `y` las etiquetas de todos los nodos.\n",
    "\n",
    "Una vez vistos los datos, podemos implementar una red neuronal de grafos sencilla. La GNN aplica una secuencia de capas de grafos (GCN, GAT o GraphConv), ReLU como función de activación y dropout para la regularización. Vamos a ver la implementación específica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RqQmkcv3o0D3"
   },
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GCN\", dp_rate=0.1, **kwargs):\n",
    "        \"\"\"\n",
    "        Entradas:\n",
    "            c_in - Dimensionalidad de las características de entrada\n",
    "            c_hidden - Dimensionalidad de las características de la oculta\n",
    "            c_out - Dimensionalidad de las características de salida. Normalmente corresponde con el número de clases de la clasificación\n",
    "            num_layers - Número de capas ocultas\n",
    "            layer_name - Nombre de técnica a usar\n",
    "            dp_rate - La \"tasa de dropout\" (dropout rate) de la red (hiperparámetro para regularizar y mejorar el rendimiento, reduciendo así el riesgo de overfitting)\n",
    "            kwargs - Argumentos adicionales (por ejemplo, el número de heads su usamos una GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer = gnn_layer_by_name[layer_name]\n",
    "\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers-1):\n",
    "            layers += [\n",
    "                gnn_layer(in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          **kwargs),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dp_rate)\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [gnn_layer(in_channels=in_channels,\n",
    "                             out_channels=c_out,\n",
    "                             **kwargs)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Entradas:\n",
    "            x - Características de entrada para cada nodo\n",
    "            edge_index - Lista de índices de aristas del grafo (notación de PyTorch geometric)\n",
    "        \"\"\"\n",
    "        for l in self.layers:\n",
    "            # Para las capas, necesitamos añadir el tensor \"edge_index\" como entrada adicional\n",
    "            # Toda capa PyTorch Geometric graph hereda la clase \"MessagePassing\", por lo tanto, podemos comprobar el tipo de clase de forma sencilla\n",
    "            if isinstance(l, geom_nn.MessagePassing):\n",
    "                x = l(x, edge_index)\n",
    "            else:\n",
    "                x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HODOfwpco0D4"
   },
   "source": [
    "Una buena práctica en las tareas a nivel de nodo consiste en crear una MLP baseline que se aplique a cada nodo de forma independiente. De esta forma podemos comprobar si la suma de la información del grafo al modelo mejora realmente la predicción, o no. También puede ocurrir que las características por nodo ya sean lo suficientemente expresivas como para apuntar claramente hacia una clase específica. Para comprobarlo, a continuación implementamos un MLP sencillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OXgzrDjBo0D4"
   },
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n",
    "        \"\"\"\n",
    "        Entradas:\n",
    "            c_in - Dimensionalidad de las características de entrada\n",
    "            c_hidden - Dimensionalidad de las características de la oculta\n",
    "            c_out - Dimensionalidad de las características de salida. Normalmente corresponde con el número de clases de la clasificación\n",
    "            num_layers - Número de capas ocultas\n",
    "            dp_rate - La \"tasa de dropout\" de la red\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers-1): #Aplicamos linealidad, funcion de activación RELU y dropout para el overfitting\n",
    "            layers += [\n",
    "                nn.Linear(in_channels, out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dp_rate)\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [nn.Linear(in_channels, c_out)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Entradas:\n",
    "            x - Características de entrada por nodo\n",
    "        \"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQX1XQX3o0D5"
   },
   "source": [
    "Por último, podemos fusionar los modelos en un módulo PyTorch Lightning que se encargue del entrenamiento, la validación y las pruebas por nosotros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mgAhRT-2o0D6"
   },
   "outputs": [],
   "source": [
    "class NodeLevelGNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model_name, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Guardar los hiperparámetros\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        if model_name == \"MLP\":\n",
    "            self.model = MLPModel(**model_kwargs)\n",
    "        else:\n",
    "            self.model = GNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.model(x, edge_index)\n",
    "\n",
    "        # Solo se calcula la pérdida en los nodos que corresponden a la máscara\n",
    "        if mode == \"train\":\n",
    "            mask = data.train_mask\n",
    "        elif mode == \"val\":\n",
    "            mask = data.val_mask\n",
    "        elif mode == \"test\":\n",
    "            mask = data.test_mask\n",
    "        else:\n",
    "            assert False, f\"Modo desconocido: {mode}\"\n",
    "\n",
    "        loss = self.loss_module(x[mask], data.y[mask]) #Pérdida\n",
    "        acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float() / mask.sum() #Eficiencia (accuracy)\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Usamos Stochastic Gradient Descent (SGD) como algoritmo de optimización, pero Adam también es una buena opción\n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.forward(batch, mode=\"train\")\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"val\")\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"test\")\n",
    "        self.log('test_acc', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW4ptUqYo0D6"
   },
   "source": [
    "Además del módulo Lightning, definimos una función de entrenamiento. Como tenemos un grafo simple, utilizamos un tamaño de lote (batch_size) de 1 para cargar datos y compartimos el mismo para el conjunto de entrenamiento, validación y prueba (la máscara se elige dentro del módulo Lightning). Además, establecemos el argumento `enable_progress_bar` a False (sirve para mostrar una barra de progreso con el progreso del entrenamiento a medida que se ejecutan las épocas, pero en este caso al tener tamaño uno carece de sentido, y se muestra solo al final)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QutHVL6do0D6"
   },
   "outputs": [],
   "source": [
    "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
    "    pl.seed_everything(42)\n",
    "    node_data_loader = geom_data.DataLoader(dataset, batch_size=1) #loader.DataLoader\n",
    "\n",
    "    # Creamos un PyTorch Lightning trainer (entrenamiento) con llamada de retorno (generation callback)\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"NodeLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=200,\n",
    "                         enable_progress_bar=False) # False porque el tamaño de la época es 1\n",
    "    trainer.logger._default_hp_metric = None # No es necesario un argumento para el logging\n",
    "\n",
    "    # Comprobamos que el modelo preentrenado existe, cargándolo y saltando el paso de entrenamiento en caso afirmativo\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"NodeLevel{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Se ha encontrado un modelo preentrenado, cargando...\")\n",
    "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything()\n",
    "        model = NodeLevelGNN(model_name=model_name, c_in=dataset.num_node_features, c_out=dataset.num_classes, **model_kwargs)\n",
    "        trainer.fit(model, node_data_loader, node_data_loader)\n",
    "        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    # Probamos el mejor modelo en el conjunto de test\n",
    "    test_result = trainer.test(model, node_data_loader, verbose=False)\n",
    "    batch = next(iter(node_data_loader))\n",
    "    batch = batch.to(model.device)\n",
    "    _, train_acc = model.forward(batch, mode=\"train\")\n",
    "    _, val_acc = model.forward(batch, mode=\"val\")\n",
    "    result = {\"train\": train_acc,\n",
    "              \"val\": val_acc,\n",
    "              \"test\": test_result[0]['test_acc']}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5CuOi7eo0D7"
   },
   "source": [
    "Por último, podemos entrenar nuestros modelos. En primer lugar, vamos a entrenar el MLP simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "87_a5yvco0D7"
   },
   "outputs": [],
   "source": [
    "#Función para mostrar los resultados\n",
    "def print_results(result_dict):\n",
    "    print(f\"\\nAccuracy:\\n\")\n",
    "    if \"train\" in result_dict:\n",
    "        print(f\"Entrenamiento: {(100.0*result_dict['train']):4.2f}%\")\n",
    "    if \"val\" in result_dict:\n",
    "        print(f\"Validación:   {(100.0*result_dict['val']):4.2f}%\")\n",
    "    print(f\"Test:  {(100.0*result_dict['test']):4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xUepWOQo0D8",
    "outputId": "7101f675-0017-4942-ae5f-9d6665c3e33d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "Global seed set to 42\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model       | MLPModel         | 23.1 K\n",
      "1 | loss_module | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.092     Total estimated model params size (MB)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2708. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:\n",
      "\n",
      "Entrenamiento: 98.57%\n",
      "Validación:   53.40%\n",
      "Test:  59.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "node_mlp_model, node_mlp_result = train_node_classifier(model_name=\"MLP\",\n",
    "                                                        dataset=cora_dataset,\n",
    "                                                        c_hidden=16,\n",
    "                                                        num_layers=2,\n",
    "                                                        dp_rate=0.1)\n",
    "\n",
    "print_results(node_mlp_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ph3U2OQObvW"
   },
   "source": [
    "**Pregunta 1:** ¿Cómo interpretas los valores de accuracy de los diferentes conjuntos? Explicación detallada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Respuesta a pregunta 1***\n",
    "\n",
    "El valor de accuracy (precisión) en del 98.57% nos dice que el modelo ha aprendido muy bien las relaciones y patrones en el conjunto de entrenamiento. Ha logrado clasificar correctamente el 98.57% de los ejemplos de entrenamiento. Pero, un valor tan alto en comparación con los conjuntos de validación y prueba sugiere que el modelo podría estar memorizando el conjunto de entrenamiento, un fenómeno conocido como overfitting. En overfitting, el modelo es tan específico a los datos de entrenamiento que pierde capacidad de generalización.\n",
    "\n",
    "Por otro lado en el conjunto de validación hemos obtenido un valor del 53.40% esto sugiere que el modelo no está generalizando bien a nuevos datos no vistos durante el entrenamiento.\n",
    "\n",
    "Por último en el conjunto de prueba hemos obtenido un valor del 59.60% es un indicador de cómo el modelo se desempeñará en el \"mundo real\". Este valor nos da una medida de la capacidad de generalización del modelo a datos completamente nuevos y no vistos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xc1CrfNo0D8"
   },
   "source": [
    "Ahora probamos con la GNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5OD__xBo0D9",
    "outputId": "5d46cb2c-f478-4034-b77a-81fa056896e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model       | GNNModel         | 23.1 K\n",
      "1 | loss_module | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.092     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:\n",
      "\n",
      "Entrenamiento: 99.29%\n",
      "Validación:   76.60%\n",
      "Test:  80.90%\n"
     ]
    }
   ],
   "source": [
    "node_gnn_model, node_gnn_result = train_node_classifier(model_name=\"GNN\",\n",
    "                                                        layer_name=\"GCN\",\n",
    "                                                        dataset=cora_dataset,\n",
    "                                                        c_hidden=16,\n",
    "                                                        num_layers=2,\n",
    "                                                        dp_rate=0.1)\n",
    "print_results(node_gnn_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3M2E-FPP7O5"
   },
   "source": [
    "**Pregunta 2:** ¿Cómo interpretas los valores de accuracy de los diferentes conjuntos ahora? Explicación detallada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5lw1Q4uQZY-"
   },
   "source": [
    "**Conclusión** Redactar la conclusión que se obtiene de esta red Cora con este modelo. Probar modificaciones para comparar y obtener mejores (o peores) resultados, y explicarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Respuesta a pregunta 2***\n",
    "\n",
    "El valor de accuracy (precisión) en del 99.29% nos dice que El modelo ha alcanzado una precisión extremadamente alta en el conjunto de entrenamiento, lo que indica que ha aprendido muy bien los patrones y relaciones en estos datos. Pese a haber obtenido un valor muy bueno en el entrenamiento, tenemos que tener cuidado con el overfitting.\n",
    "\n",
    "En el conjunto de validación hemos obtenido un valor del 76.60% esto sugiere que el modelo GNN está generalizando mejor a datos no vistos durante el entrenamiento.\n",
    "\n",
    "Por último en el conjunto de prueba hemos obtenido un valor del 80.90% La precisión en el conjunto de prueba también es alta, lo que es un indicador positivo de la capacidad del modelo para generalizar a nuevos datos.\n",
    "\n",
    "La arquitectura GNN parece ser más adecuada para este tipo de datos estructurados en grafos, como el dataset Cora, permitiendo una mejor captura de las relaciones y patrones subyacentes en los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m adjusted_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Configurar el optimizador con weight decay\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39madjusted_lr, weight_decay\u001b[38;5;241m=\u001b[39madjusted_weight_decay)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con los parámetros ajustados\u001b[39;00m\n\u001b[1;32m     11\u001b[0m node_gnn_model, node_gnn_result \u001b[38;5;241m=\u001b[39m train_node_classifier(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGNN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m                                                         layer_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGCN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m                                                         dataset\u001b[38;5;241m=\u001b[39mcora_dataset,\n\u001b[1;32m     14\u001b[0m                                                         c_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     15\u001b[0m                                                         num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     16\u001b[0m                                                         dp_rate\u001b[38;5;241m=\u001b[39madjusted_dp_rate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# INTENTO DE OPTIMIZACIÓN PREGUNTA 2\n",
    "# Ajustar parámetros para regularización y optimización de hiperparámetros\n",
    "adjusted_dp_rate = 0.2\n",
    "adjusted_weight_decay = 1e-5\n",
    "adjusted_lr = 0.05\n",
    "\n",
    "# Configurar el optimizador con weight decay\n",
    "optimizer = optim.SGD(model.parameters(), lr=adjusted_lr, weight_decay=adjusted_weight_decay)\n",
    "\n",
    "# Entrenar el modelo con los parámetros ajustados\n",
    "node_gnn_model, node_gnn_result = train_node_classifier(model_name=\"GNN\",\n",
    "                                                        layer_name=\"GCN\",\n",
    "                                                        dataset=cora_dataset,\n",
    "                                                        c_hidden=16,\n",
    "                                                        num_layers=2,\n",
    "                                                        dp_rate=adjusted_dp_rate)\n",
    "\n",
    "# Evaluar y comparar los resultados\n",
    "print_results(node_gnn_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Dropout es una técnica de regularización utilizada para prevenir el sobreajuste en redes neuronales. Durante el entrenamiento, Dropout \"apaga\" aleatoriamente algunas neuronas de la red con una probabilidad\n",
    "\n",
    "**Dropout:** el parámetro dp_rate en tu modelo para cambiar la tasa de dropout. Un valor más alto podría ayudar a prevenir el sobreajuste.\n",
    "\n",
    "El Weight Decay es otra técnica de regularización que añade una penalización L2 a la función de pérdida, que es proporcional a la magnitud de los pesos\n",
    "**Weight Decay**:Esto añade una penalización L2 a los pesos durante el entrenamiento, lo que puede ayudar a prevenir el sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1sBtVhZo0D-"
   },
   "source": [
    "### A nivel de aristas (Edge-level tasks). Ejemplo:  Predicción de enlaces\n",
    "\n",
    "En algunas aplicaciones, es posible que tengamos que predecir a nivel de arista en lugar de a nivel de nodo. La tarea a nivel de arista más común en GNN es la predicción de enlaces (link prediction). Significa que, dado un grafo, queremos predecir si habrá o debería haber una arista o enlace entre dos nodos. Por ejemplo, en una red social, para proponerte nuevos amigos. De nuevo, la información a nivel de grafo puede ser crucial para realizar esta tarea. La predicción del resultado se realiza normalmente aplicando una métrica de similitud sobre un par de características de los nodos, que debería ser 1 si existe relación y 0 en caso contrario.\n",
    "\n",
    "Siguiendo el mismo ejemplo que antes (Cora dataset), ahora no vamos a clasificar de que tipo es cada publicación científica, sino vamos a predecir que artículos deberían citarse entre sí (link prediction). En la práctica, es añadir nuevas aristas al grafo. Para ello, vamos a usar el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUkAylWaG_3T",
    "outputId": "ba30f86c-0c00-46d5-916a-d10e53ac0d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6930, Val: 0.6749, Test: 0.6448\n",
      "Epoch: 002, Loss: 0.6815, Val: 0.6672, Test: 0.6381\n",
      "Epoch: 003, Loss: 0.7152, Val: 0.6706, Test: 0.6438\n",
      "Epoch: 004, Loss: 0.6770, Val: 0.6831, Test: 0.6635\n",
      "Epoch: 005, Loss: 0.6851, Val: 0.7042, Test: 0.6904\n",
      "Epoch: 006, Loss: 0.6888, Val: 0.7285, Test: 0.7178\n",
      "Epoch: 007, Loss: 0.6898, Val: 0.7235, Test: 0.7142\n",
      "Epoch: 008, Loss: 0.6893, Val: 0.7020, Test: 0.6945\n",
      "Epoch: 009, Loss: 0.6874, Val: 0.6867, Test: 0.6767\n",
      "Epoch: 010, Loss: 0.6836, Val: 0.6751, Test: 0.6633\n",
      "Epoch: 011, Loss: 0.6778, Val: 0.6684, Test: 0.6553\n",
      "Epoch: 012, Loss: 0.6735, Val: 0.6676, Test: 0.6526\n",
      "Epoch: 013, Loss: 0.6757, Val: 0.6729, Test: 0.6574\n",
      "Epoch: 014, Loss: 0.6707, Val: 0.6876, Test: 0.6714\n",
      "Epoch: 015, Loss: 0.6620, Val: 0.7151, Test: 0.6969\n",
      "Epoch: 016, Loss: 0.6567, Val: 0.7426, Test: 0.7221\n",
      "Epoch: 017, Loss: 0.6497, Val: 0.7558, Test: 0.7285\n",
      "Epoch: 018, Loss: 0.6407, Val: 0.7588, Test: 0.7220\n",
      "Epoch: 019, Loss: 0.6288, Val: 0.7621, Test: 0.7204\n",
      "Epoch: 020, Loss: 0.6143, Val: 0.7723, Test: 0.7306\n",
      "Epoch: 021, Loss: 0.5977, Val: 0.7774, Test: 0.7438\n",
      "Epoch: 022, Loss: 0.5882, Val: 0.7695, Test: 0.7466\n",
      "Epoch: 023, Loss: 0.5822, Val: 0.7762, Test: 0.7406\n",
      "Epoch: 024, Loss: 0.5726, Val: 0.7824, Test: 0.7321\n",
      "Epoch: 025, Loss: 0.5704, Val: 0.7808, Test: 0.7333\n",
      "Epoch: 026, Loss: 0.5607, Val: 0.7715, Test: 0.7362\n",
      "Epoch: 027, Loss: 0.5632, Val: 0.7748, Test: 0.7390\n",
      "Epoch: 028, Loss: 0.5503, Val: 0.7855, Test: 0.7432\n",
      "Epoch: 029, Loss: 0.5447, Val: 0.7919, Test: 0.7491\n",
      "Epoch: 030, Loss: 0.5500, Val: 0.7915, Test: 0.7608\n",
      "Epoch: 031, Loss: 0.5395, Val: 0.7918, Test: 0.7703\n",
      "Epoch: 032, Loss: 0.5348, Val: 0.7976, Test: 0.7758\n",
      "Epoch: 033, Loss: 0.5313, Val: 0.8054, Test: 0.7796\n",
      "Epoch: 034, Loss: 0.5278, Val: 0.8135, Test: 0.7795\n",
      "Epoch: 035, Loss: 0.5163, Val: 0.8197, Test: 0.7781\n",
      "Epoch: 036, Loss: 0.5138, Val: 0.8205, Test: 0.7781\n",
      "Epoch: 037, Loss: 0.5081, Val: 0.8187, Test: 0.7824\n",
      "Epoch: 038, Loss: 0.5119, Val: 0.8166, Test: 0.7874\n",
      "Epoch: 039, Loss: 0.5019, Val: 0.8186, Test: 0.7898\n",
      "Epoch: 040, Loss: 0.5045, Val: 0.8218, Test: 0.7852\n",
      "Epoch: 041, Loss: 0.5087, Val: 0.8241, Test: 0.7826\n",
      "Epoch: 042, Loss: 0.5074, Val: 0.8224, Test: 0.7868\n",
      "Epoch: 043, Loss: 0.4980, Val: 0.8184, Test: 0.7946\n",
      "Epoch: 044, Loss: 0.5097, Val: 0.8210, Test: 0.7923\n",
      "Epoch: 045, Loss: 0.5001, Val: 0.8241, Test: 0.7893\n",
      "Epoch: 046, Loss: 0.5044, Val: 0.8223, Test: 0.7956\n",
      "Epoch: 047, Loss: 0.4989, Val: 0.8196, Test: 0.8046\n",
      "Epoch: 048, Loss: 0.5016, Val: 0.8193, Test: 0.8073\n",
      "Epoch: 049, Loss: 0.4962, Val: 0.8227, Test: 0.8035\n",
      "Epoch: 050, Loss: 0.4930, Val: 0.8266, Test: 0.8028\n",
      "Epoch: 051, Loss: 0.4849, Val: 0.8298, Test: 0.8110\n",
      "Epoch: 052, Loss: 0.4888, Val: 0.8292, Test: 0.8206\n",
      "Epoch: 053, Loss: 0.4896, Val: 0.8266, Test: 0.8259\n",
      "Epoch: 054, Loss: 0.4936, Val: 0.8282, Test: 0.8252\n",
      "Epoch: 055, Loss: 0.4847, Val: 0.8332, Test: 0.8256\n",
      "Epoch: 056, Loss: 0.4839, Val: 0.8386, Test: 0.8317\n",
      "Epoch: 057, Loss: 0.4806, Val: 0.8403, Test: 0.8418\n",
      "Epoch: 058, Loss: 0.4827, Val: 0.8408, Test: 0.8470\n",
      "Epoch: 059, Loss: 0.4893, Val: 0.8474, Test: 0.8451\n",
      "Epoch: 060, Loss: 0.4755, Val: 0.8547, Test: 0.8408\n",
      "Epoch: 061, Loss: 0.4787, Val: 0.8608, Test: 0.8474\n",
      "Epoch: 062, Loss: 0.4721, Val: 0.8644, Test: 0.8586\n",
      "Epoch: 063, Loss: 0.4693, Val: 0.8684, Test: 0.8639\n",
      "Epoch: 064, Loss: 0.4655, Val: 0.8757, Test: 0.8635\n",
      "Epoch: 065, Loss: 0.4572, Val: 0.8821, Test: 0.8617\n",
      "Epoch: 066, Loss: 0.4571, Val: 0.8845, Test: 0.8636\n",
      "Epoch: 067, Loss: 0.4677, Val: 0.8869, Test: 0.8662\n",
      "Epoch: 068, Loss: 0.4658, Val: 0.8886, Test: 0.8692\n",
      "Epoch: 069, Loss: 0.4655, Val: 0.8901, Test: 0.8708\n",
      "Epoch: 070, Loss: 0.4673, Val: 0.8923, Test: 0.8697\n",
      "Epoch: 071, Loss: 0.4671, Val: 0.8933, Test: 0.8687\n",
      "Epoch: 072, Loss: 0.4547, Val: 0.8937, Test: 0.8699\n",
      "Epoch: 073, Loss: 0.4567, Val: 0.8930, Test: 0.8733\n",
      "Epoch: 074, Loss: 0.4634, Val: 0.8914, Test: 0.8761\n",
      "Epoch: 075, Loss: 0.4538, Val: 0.8913, Test: 0.8771\n",
      "Epoch: 076, Loss: 0.4579, Val: 0.8905, Test: 0.8764\n",
      "Epoch: 077, Loss: 0.4521, Val: 0.8889, Test: 0.8758\n",
      "Epoch: 078, Loss: 0.4534, Val: 0.8878, Test: 0.8750\n",
      "Epoch: 079, Loss: 0.4517, Val: 0.8873, Test: 0.8754\n",
      "Epoch: 080, Loss: 0.4532, Val: 0.8886, Test: 0.8749\n",
      "Epoch: 081, Loss: 0.4560, Val: 0.8908, Test: 0.8749\n",
      "Epoch: 082, Loss: 0.4492, Val: 0.8927, Test: 0.8749\n",
      "Epoch: 083, Loss: 0.4575, Val: 0.8943, Test: 0.8756\n",
      "Epoch: 084, Loss: 0.4462, Val: 0.8949, Test: 0.8762\n",
      "Epoch: 085, Loss: 0.4543, Val: 0.8946, Test: 0.8779\n",
      "Epoch: 086, Loss: 0.4439, Val: 0.8964, Test: 0.8792\n",
      "Epoch: 087, Loss: 0.4495, Val: 0.8996, Test: 0.8791\n",
      "Epoch: 088, Loss: 0.4503, Val: 0.9021, Test: 0.8782\n",
      "Epoch: 089, Loss: 0.4427, Val: 0.9025, Test: 0.8792\n",
      "Epoch: 090, Loss: 0.4406, Val: 0.9003, Test: 0.8817\n",
      "Epoch: 091, Loss: 0.4392, Val: 0.9008, Test: 0.8837\n",
      "Epoch: 092, Loss: 0.4488, Val: 0.9023, Test: 0.8847\n",
      "Epoch: 093, Loss: 0.4429, Val: 0.9027, Test: 0.8838\n",
      "Epoch: 094, Loss: 0.4478, Val: 0.9029, Test: 0.8824\n",
      "Epoch: 095, Loss: 0.4445, Val: 0.9003, Test: 0.8826\n",
      "Epoch: 096, Loss: 0.4363, Val: 0.9005, Test: 0.8852\n",
      "Epoch: 097, Loss: 0.4428, Val: 0.9019, Test: 0.8868\n",
      "Epoch: 098, Loss: 0.4401, Val: 0.9031, Test: 0.8860\n",
      "Epoch: 099, Loss: 0.4370, Val: 0.9031, Test: 0.8846\n",
      "Epoch: 100, Loss: 0.4443, Val: 0.9027, Test: 0.8837\n",
      "Final Test: 0.8860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loc(\"mps_not_equal\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/75428952-3aa4-11ee-8b65-46d450270006/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":253:0)): error: 'anec.not_equal_zero' op Invalid configuration for the following reasons: Tensor dimensions N1D1C1H1W7333264 are not within supported range, N[1-65536]D[1-16384]C[1-65536]H[1-16384]W[1-16384].\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/75428952-3aa4-11ee-8b65-46d450270006/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.not_equal_zero' op Invalid configuration for the following reasons: Tensor dimensions N1D1C1H1W7333264 are not within supported range, N[1-65536]D[1-16384]C[1-65536]H[1-16384]W[1-16384].\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "#Definimos una serie de transformaciones secuencialmente y ordenado.\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(), #Normalización de características en un conjunto de datos\n",
    "    T.ToDevice(device), #Transferimos los tensores o modelos a un dispositivo de hardware específico definido en \"device\"\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, #Realiza una división aleatoria de los datos a nivel de aristas en tres conjuntos de entrenamiento, validación y test\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "#Cargamos el dataset, aplicando las transformaciones\n",
    "cora_dataset = Planetoid(root=DATASET_PATH, name='Cora', transform=transform)\n",
    "#Como hemos dividido el dataset en tres conjuntos con RandomLinkSplit, los datos están en una lista de tuplas (train_data, val_data, test_data)\n",
    "train_data, val_data, test_data = cora_dataset[0]\n",
    "\n",
    "#Net sirve para definir modelos en PyTorch, heredando de torch.nn.Module. Obtenemos un modelo personalizado que se puede utilizar para definir arquitecturas de redes neuronales\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "#Creamos el modelo personalizado con nuestro dataset, y definimos el optimizador Adam y la función de perdida BCEWithLogitsLoss\n",
    "model = Net(cora_dataset.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "#Entrenamiento de la red\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad() #Reseteo de los gradientes a cero antes de entrenar\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    #Realizamos una nueva ronda de muestreo negativo para cada época de entrenamiento\n",
    "    #Sirve para abordar el problema de la eficiencia computacional al trabajar con grandes conjuntos de datos.\n",
    "    #La técnica se utiliza para reducir el número de ejemplos de entrenamiento, lo que acelera significativamente el proceso de entrenamiento sin sacrificar la calidad del modelo\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "#Prueba de los datos, obteniendo el resultado con la medida ROC AUC\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101): #Usamos 100 épocas\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unTCuFUOPPAx"
   },
   "source": [
    "**Pregunta 3:** ¿Qué es el ROC AUC score? ¿Para qué sirve? ¿En qué casos es mejor usar accuracy y en cuales AUC? Modificar el código para obtener los resultados con accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta a pregunta 3**\n",
    "El ROC AUC Score es una métrica de evaluación para problemas de clasificación binaria.\n",
    "ROC es \"Receiver Operating Characteristics\" \n",
    "AUC significa Area under the curve\n",
    "\n",
    "ROC = muestra el rendimiento de un modelo de clasificación en todos los umbrales de clasificación. Tasa de verdaderos positivos y tasa de falsos positivos\n",
    "AUC = Es el área bajo la curva ROC, representa un modelo perfecto\n",
    "\n",
    "El ROC AUC sirve para cuando las clases están desbalanceadas, además sirve cuando se necesita dar igual importancia a la Tasa de Verdaderos Positivos y la Tasa de Falsos Positivos, y es útil para comparar diferentes modelos de clasificación.\n",
    "\n",
    "Accuracy es mejor utilizarlo cuando las clases están balanceadas y los errores de clasificación para cada clase tienen un costo similar.\n",
    "AUC es mejor utilizarlo cuando las clases están desbalanceadas y el error de clasificación de cada una tiene diferente coste.\n",
    "\n",
    "Para obtener los resultados con Accuracy voy a modificar el código ya implementado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.4397, Val Accuracy: 0.7490, Test Accuracy: 0.7524\n",
      "Epoch: 002, Loss: 0.4379, Val Accuracy: 0.7490, Test Accuracy: 0.7476\n",
      "Epoch: 003, Loss: 0.4391, Val Accuracy: 0.7548, Test Accuracy: 0.7486\n",
      "Epoch: 004, Loss: 0.4474, Val Accuracy: 0.7529, Test Accuracy: 0.7467\n",
      "Epoch: 005, Loss: 0.4302, Val Accuracy: 0.7548, Test Accuracy: 0.7467\n",
      "Epoch: 006, Loss: 0.4380, Val Accuracy: 0.7567, Test Accuracy: 0.7505\n",
      "Epoch: 007, Loss: 0.4394, Val Accuracy: 0.7548, Test Accuracy: 0.7457\n",
      "Epoch: 008, Loss: 0.4352, Val Accuracy: 0.7529, Test Accuracy: 0.7448\n",
      "Epoch: 009, Loss: 0.4357, Val Accuracy: 0.7529, Test Accuracy: 0.7391\n",
      "Epoch: 010, Loss: 0.4340, Val Accuracy: 0.7567, Test Accuracy: 0.7438\n",
      "Epoch: 011, Loss: 0.4400, Val Accuracy: 0.7567, Test Accuracy: 0.7524\n",
      "Epoch: 012, Loss: 0.4372, Val Accuracy: 0.7433, Test Accuracy: 0.7524\n",
      "Epoch: 013, Loss: 0.4408, Val Accuracy: 0.7357, Test Accuracy: 0.7476\n",
      "Epoch: 014, Loss: 0.4322, Val Accuracy: 0.7376, Test Accuracy: 0.7438\n",
      "Epoch: 015, Loss: 0.4342, Val Accuracy: 0.7452, Test Accuracy: 0.7391\n",
      "Epoch: 016, Loss: 0.4349, Val Accuracy: 0.7414, Test Accuracy: 0.7410\n",
      "Epoch: 017, Loss: 0.4309, Val Accuracy: 0.7510, Test Accuracy: 0.7505\n",
      "Epoch: 018, Loss: 0.4278, Val Accuracy: 0.7433, Test Accuracy: 0.7543\n",
      "Epoch: 019, Loss: 0.4371, Val Accuracy: 0.7452, Test Accuracy: 0.7476\n",
      "Epoch: 020, Loss: 0.4296, Val Accuracy: 0.7529, Test Accuracy: 0.7495\n",
      "Epoch: 021, Loss: 0.4279, Val Accuracy: 0.7510, Test Accuracy: 0.7438\n",
      "Epoch: 022, Loss: 0.4323, Val Accuracy: 0.7490, Test Accuracy: 0.7467\n",
      "Epoch: 023, Loss: 0.4331, Val Accuracy: 0.7452, Test Accuracy: 0.7552\n",
      "Epoch: 024, Loss: 0.4419, Val Accuracy: 0.7586, Test Accuracy: 0.7562\n",
      "Epoch: 025, Loss: 0.4331, Val Accuracy: 0.7548, Test Accuracy: 0.7533\n",
      "Epoch: 026, Loss: 0.4314, Val Accuracy: 0.7586, Test Accuracy: 0.7543\n",
      "Epoch: 027, Loss: 0.4351, Val Accuracy: 0.7586, Test Accuracy: 0.7457\n",
      "Epoch: 028, Loss: 0.4294, Val Accuracy: 0.7605, Test Accuracy: 0.7486\n",
      "Epoch: 029, Loss: 0.4281, Val Accuracy: 0.7548, Test Accuracy: 0.7533\n",
      "Epoch: 030, Loss: 0.4305, Val Accuracy: 0.7586, Test Accuracy: 0.7581\n",
      "Epoch: 031, Loss: 0.4276, Val Accuracy: 0.7586, Test Accuracy: 0.7514\n",
      "Epoch: 032, Loss: 0.4294, Val Accuracy: 0.7643, Test Accuracy: 0.7505\n",
      "Epoch: 033, Loss: 0.4325, Val Accuracy: 0.7662, Test Accuracy: 0.7505\n",
      "Epoch: 034, Loss: 0.4263, Val Accuracy: 0.7643, Test Accuracy: 0.7514\n",
      "Epoch: 035, Loss: 0.4321, Val Accuracy: 0.7643, Test Accuracy: 0.7457\n",
      "Epoch: 036, Loss: 0.4284, Val Accuracy: 0.7662, Test Accuracy: 0.7486\n",
      "Epoch: 037, Loss: 0.4236, Val Accuracy: 0.7605, Test Accuracy: 0.7524\n",
      "Epoch: 038, Loss: 0.4287, Val Accuracy: 0.7624, Test Accuracy: 0.7514\n",
      "Epoch: 039, Loss: 0.4195, Val Accuracy: 0.7719, Test Accuracy: 0.7524\n",
      "Epoch: 040, Loss: 0.4317, Val Accuracy: 0.7719, Test Accuracy: 0.7486\n",
      "Epoch: 041, Loss: 0.4304, Val Accuracy: 0.7700, Test Accuracy: 0.7476\n",
      "Epoch: 042, Loss: 0.4299, Val Accuracy: 0.7681, Test Accuracy: 0.7514\n",
      "Epoch: 043, Loss: 0.4309, Val Accuracy: 0.7624, Test Accuracy: 0.7533\n",
      "Epoch: 044, Loss: 0.4295, Val Accuracy: 0.7700, Test Accuracy: 0.7562\n",
      "Epoch: 045, Loss: 0.4226, Val Accuracy: 0.7700, Test Accuracy: 0.7552\n",
      "Epoch: 046, Loss: 0.4247, Val Accuracy: 0.7662, Test Accuracy: 0.7562\n",
      "Epoch: 047, Loss: 0.4377, Val Accuracy: 0.7643, Test Accuracy: 0.7562\n",
      "Epoch: 048, Loss: 0.4265, Val Accuracy: 0.7643, Test Accuracy: 0.7581\n",
      "Epoch: 049, Loss: 0.4291, Val Accuracy: 0.7624, Test Accuracy: 0.7543\n",
      "Epoch: 050, Loss: 0.4287, Val Accuracy: 0.7643, Test Accuracy: 0.7543\n",
      "Epoch: 051, Loss: 0.4234, Val Accuracy: 0.7681, Test Accuracy: 0.7533\n",
      "Epoch: 052, Loss: 0.4303, Val Accuracy: 0.7681, Test Accuracy: 0.7524\n",
      "Epoch: 053, Loss: 0.4186, Val Accuracy: 0.7662, Test Accuracy: 0.7533\n",
      "Epoch: 054, Loss: 0.4252, Val Accuracy: 0.7681, Test Accuracy: 0.7495\n",
      "Epoch: 055, Loss: 0.4292, Val Accuracy: 0.7643, Test Accuracy: 0.7552\n",
      "Epoch: 056, Loss: 0.4175, Val Accuracy: 0.7662, Test Accuracy: 0.7552\n",
      "Epoch: 057, Loss: 0.4255, Val Accuracy: 0.7624, Test Accuracy: 0.7514\n",
      "Epoch: 058, Loss: 0.4174, Val Accuracy: 0.7719, Test Accuracy: 0.7495\n",
      "Epoch: 059, Loss: 0.4307, Val Accuracy: 0.7719, Test Accuracy: 0.7486\n",
      "Epoch: 060, Loss: 0.4289, Val Accuracy: 0.7719, Test Accuracy: 0.7505\n",
      "Epoch: 061, Loss: 0.4238, Val Accuracy: 0.7738, Test Accuracy: 0.7543\n",
      "Epoch: 062, Loss: 0.4206, Val Accuracy: 0.7700, Test Accuracy: 0.7505\n",
      "Epoch: 063, Loss: 0.4159, Val Accuracy: 0.7700, Test Accuracy: 0.7514\n",
      "Epoch: 064, Loss: 0.4205, Val Accuracy: 0.7719, Test Accuracy: 0.7514\n",
      "Epoch: 065, Loss: 0.4254, Val Accuracy: 0.7738, Test Accuracy: 0.7533\n",
      "Epoch: 066, Loss: 0.4205, Val Accuracy: 0.7776, Test Accuracy: 0.7571\n",
      "Epoch: 067, Loss: 0.4195, Val Accuracy: 0.7776, Test Accuracy: 0.7552\n",
      "Epoch: 068, Loss: 0.4204, Val Accuracy: 0.7738, Test Accuracy: 0.7562\n",
      "Epoch: 069, Loss: 0.4243, Val Accuracy: 0.7719, Test Accuracy: 0.7552\n",
      "Epoch: 070, Loss: 0.4197, Val Accuracy: 0.7738, Test Accuracy: 0.7581\n",
      "Epoch: 071, Loss: 0.4226, Val Accuracy: 0.7719, Test Accuracy: 0.7590\n",
      "Epoch: 072, Loss: 0.4233, Val Accuracy: 0.7719, Test Accuracy: 0.7609\n",
      "Epoch: 073, Loss: 0.4254, Val Accuracy: 0.7700, Test Accuracy: 0.7571\n",
      "Epoch: 074, Loss: 0.4225, Val Accuracy: 0.7700, Test Accuracy: 0.7533\n",
      "Epoch: 075, Loss: 0.4217, Val Accuracy: 0.7719, Test Accuracy: 0.7524\n",
      "Epoch: 076, Loss: 0.4182, Val Accuracy: 0.7719, Test Accuracy: 0.7533\n",
      "Epoch: 077, Loss: 0.4152, Val Accuracy: 0.7624, Test Accuracy: 0.7562\n",
      "Epoch: 078, Loss: 0.4136, Val Accuracy: 0.7700, Test Accuracy: 0.7552\n",
      "Epoch: 079, Loss: 0.4134, Val Accuracy: 0.7738, Test Accuracy: 0.7524\n",
      "Epoch: 080, Loss: 0.4182, Val Accuracy: 0.7795, Test Accuracy: 0.7524\n",
      "Epoch: 081, Loss: 0.4120, Val Accuracy: 0.7795, Test Accuracy: 0.7552\n",
      "Epoch: 082, Loss: 0.4213, Val Accuracy: 0.7833, Test Accuracy: 0.7533\n",
      "Epoch: 083, Loss: 0.4192, Val Accuracy: 0.7757, Test Accuracy: 0.7514\n",
      "Epoch: 084, Loss: 0.4220, Val Accuracy: 0.7795, Test Accuracy: 0.7562\n",
      "Epoch: 085, Loss: 0.4159, Val Accuracy: 0.7757, Test Accuracy: 0.7505\n",
      "Epoch: 086, Loss: 0.4164, Val Accuracy: 0.7795, Test Accuracy: 0.7467\n",
      "Epoch: 087, Loss: 0.4184, Val Accuracy: 0.7814, Test Accuracy: 0.7533\n",
      "Epoch: 088, Loss: 0.4152, Val Accuracy: 0.7757, Test Accuracy: 0.7486\n",
      "Epoch: 089, Loss: 0.4143, Val Accuracy: 0.7757, Test Accuracy: 0.7467\n",
      "Epoch: 090, Loss: 0.4193, Val Accuracy: 0.7852, Test Accuracy: 0.7495\n",
      "Epoch: 091, Loss: 0.4140, Val Accuracy: 0.7795, Test Accuracy: 0.7505\n",
      "Epoch: 092, Loss: 0.4154, Val Accuracy: 0.7719, Test Accuracy: 0.7486\n",
      "Epoch: 093, Loss: 0.4182, Val Accuracy: 0.7738, Test Accuracy: 0.7505\n",
      "Epoch: 094, Loss: 0.4103, Val Accuracy: 0.7776, Test Accuracy: 0.7495\n",
      "Epoch: 095, Loss: 0.4119, Val Accuracy: 0.7795, Test Accuracy: 0.7533\n",
      "Epoch: 096, Loss: 0.4121, Val Accuracy: 0.7795, Test Accuracy: 0.7495\n",
      "Epoch: 097, Loss: 0.4197, Val Accuracy: 0.7814, Test Accuracy: 0.7476\n",
      "Epoch: 098, Loss: 0.4148, Val Accuracy: 0.7681, Test Accuracy: 0.7486\n",
      "Epoch: 099, Loss: 0.4142, Val Accuracy: 0.7586, Test Accuracy: 0.7486\n",
      "Epoch: 100, Loss: 0.4185, Val Accuracy: 0.7681, Test Accuracy: 0.7505\n"
     ]
    }
   ],
   "source": [
    "# Se utiliza para desactivar el cálculo de gradientes\n",
    "@torch.no_grad()\n",
    "def test_accuracy(data):\n",
    "    # Pone el modelo en modo de evaluación\n",
    "    model.eval()\n",
    "    # Calcula las representaciones codificadas de los nodos del grafo utilizando el método encode del modelo.\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    #Decodifica las representaciones de los nodos para obtener las predicciones del modelo, aplica la función sigmoid para obtener probabilidades y reformatea el tensor resultante.\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    #Decodifica las representaciones de los nodos para obtener las predicciones del modelo, aplica la función sigmoid para obtener probabilidades y reformatea el tensor resultante.\n",
    "    predictions = (out > 0.5).float() # Convertir probabilidades a etiquetas binarias\n",
    "    # Calcula el número de predicciones correctas comparando las predicciones con las etiquetas verdaderas.\n",
    "    correct = (predictions == data.edge_label).float().sum()\n",
    "    # Calcula la precisión (accuracy) como el número de predicciones correctas dividido por el número total de etiquetas.\n",
    "    accuracy = correct / len(data.edge_label)\n",
    "    \n",
    "    return accuracy.item()\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_accuracy_score = test_accuracy(val_data)\n",
    "    test_accuracy_score = test_accuracy(test_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Accuracy: {val_accuracy_score:.4f}, Test Accuracy: {test_accuracy_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xal23Mp4QJP6"
   },
   "source": [
    "**Ejercicio 4:** Modificar el código y realizar una gráfica de cómo van evolucionando los valores en los diferentes conjuntos a lo largo de las épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.3892, Val Accuracy: 0.7738, Test Accuracy: 0.7381\n",
      "Epoch: 002, Loss: 0.3881, Val Accuracy: 0.7662, Test Accuracy: 0.7381\n",
      "Epoch: 003, Loss: 0.3920, Val Accuracy: 0.7624, Test Accuracy: 0.7467\n",
      "Epoch: 004, Loss: 0.3871, Val Accuracy: 0.7605, Test Accuracy: 0.7448\n",
      "Epoch: 005, Loss: 0.3935, Val Accuracy: 0.7681, Test Accuracy: 0.7429\n",
      "Epoch: 006, Loss: 0.3886, Val Accuracy: 0.7700, Test Accuracy: 0.7343\n",
      "Epoch: 007, Loss: 0.3956, Val Accuracy: 0.7662, Test Accuracy: 0.7334\n",
      "Epoch: 008, Loss: 0.3900, Val Accuracy: 0.7719, Test Accuracy: 0.7353\n",
      "Epoch: 009, Loss: 0.3906, Val Accuracy: 0.7624, Test Accuracy: 0.7381\n",
      "Epoch: 010, Loss: 0.3905, Val Accuracy: 0.7662, Test Accuracy: 0.7362\n",
      "Epoch: 011, Loss: 0.3908, Val Accuracy: 0.7643, Test Accuracy: 0.7372\n",
      "Epoch: 012, Loss: 0.3919, Val Accuracy: 0.7624, Test Accuracy: 0.7372\n",
      "Epoch: 013, Loss: 0.3873, Val Accuracy: 0.7643, Test Accuracy: 0.7381\n",
      "Epoch: 014, Loss: 0.3864, Val Accuracy: 0.7662, Test Accuracy: 0.7410\n",
      "Epoch: 015, Loss: 0.3904, Val Accuracy: 0.7567, Test Accuracy: 0.7391\n",
      "Epoch: 016, Loss: 0.3886, Val Accuracy: 0.7471, Test Accuracy: 0.7362\n",
      "Epoch: 017, Loss: 0.3852, Val Accuracy: 0.7529, Test Accuracy: 0.7419\n",
      "Epoch: 018, Loss: 0.3880, Val Accuracy: 0.7681, Test Accuracy: 0.7476\n",
      "Epoch: 019, Loss: 0.3928, Val Accuracy: 0.7605, Test Accuracy: 0.7381\n",
      "Epoch: 020, Loss: 0.3913, Val Accuracy: 0.7567, Test Accuracy: 0.7381\n",
      "Epoch: 021, Loss: 0.3870, Val Accuracy: 0.7567, Test Accuracy: 0.7324\n",
      "Epoch: 022, Loss: 0.3928, Val Accuracy: 0.7529, Test Accuracy: 0.7372\n",
      "Epoch: 023, Loss: 0.3909, Val Accuracy: 0.7567, Test Accuracy: 0.7429\n",
      "Epoch: 024, Loss: 0.3938, Val Accuracy: 0.7548, Test Accuracy: 0.7362\n",
      "Epoch: 025, Loss: 0.3896, Val Accuracy: 0.7548, Test Accuracy: 0.7315\n",
      "Epoch: 026, Loss: 0.3906, Val Accuracy: 0.7586, Test Accuracy: 0.7391\n",
      "Epoch: 027, Loss: 0.3921, Val Accuracy: 0.7586, Test Accuracy: 0.7362\n",
      "Epoch: 028, Loss: 0.3925, Val Accuracy: 0.7586, Test Accuracy: 0.7353\n",
      "Epoch: 029, Loss: 0.3890, Val Accuracy: 0.7548, Test Accuracy: 0.7268\n",
      "Epoch: 030, Loss: 0.3946, Val Accuracy: 0.7548, Test Accuracy: 0.7239\n",
      "Epoch: 031, Loss: 0.3892, Val Accuracy: 0.7586, Test Accuracy: 0.7315\n",
      "Epoch: 032, Loss: 0.3920, Val Accuracy: 0.7643, Test Accuracy: 0.7343\n",
      "Epoch: 033, Loss: 0.3893, Val Accuracy: 0.7624, Test Accuracy: 0.7362\n",
      "Epoch: 034, Loss: 0.3843, Val Accuracy: 0.7662, Test Accuracy: 0.7306\n",
      "Epoch: 035, Loss: 0.3884, Val Accuracy: 0.7643, Test Accuracy: 0.7353\n",
      "Epoch: 036, Loss: 0.3832, Val Accuracy: 0.7700, Test Accuracy: 0.7306\n",
      "Epoch: 037, Loss: 0.3866, Val Accuracy: 0.7624, Test Accuracy: 0.7343\n",
      "Epoch: 038, Loss: 0.3873, Val Accuracy: 0.7681, Test Accuracy: 0.7353\n",
      "Epoch: 039, Loss: 0.3930, Val Accuracy: 0.7624, Test Accuracy: 0.7353\n",
      "Epoch: 040, Loss: 0.3875, Val Accuracy: 0.7605, Test Accuracy: 0.7362\n",
      "Epoch: 041, Loss: 0.3936, Val Accuracy: 0.7586, Test Accuracy: 0.7391\n",
      "Epoch: 042, Loss: 0.3853, Val Accuracy: 0.7605, Test Accuracy: 0.7419\n",
      "Epoch: 043, Loss: 0.3911, Val Accuracy: 0.7586, Test Accuracy: 0.7391\n",
      "Epoch: 044, Loss: 0.3856, Val Accuracy: 0.7529, Test Accuracy: 0.7438\n",
      "Epoch: 045, Loss: 0.3879, Val Accuracy: 0.7529, Test Accuracy: 0.7438\n",
      "Epoch: 046, Loss: 0.3855, Val Accuracy: 0.7548, Test Accuracy: 0.7438\n",
      "Epoch: 047, Loss: 0.3876, Val Accuracy: 0.7548, Test Accuracy: 0.7410\n",
      "Epoch: 048, Loss: 0.3931, Val Accuracy: 0.7567, Test Accuracy: 0.7448\n",
      "Epoch: 049, Loss: 0.3887, Val Accuracy: 0.7452, Test Accuracy: 0.7448\n",
      "Epoch: 050, Loss: 0.3900, Val Accuracy: 0.7452, Test Accuracy: 0.7410\n",
      "Epoch: 051, Loss: 0.3870, Val Accuracy: 0.7490, Test Accuracy: 0.7372\n",
      "Epoch: 052, Loss: 0.3870, Val Accuracy: 0.7567, Test Accuracy: 0.7410\n",
      "Epoch: 053, Loss: 0.3888, Val Accuracy: 0.7605, Test Accuracy: 0.7400\n",
      "Epoch: 054, Loss: 0.3926, Val Accuracy: 0.7605, Test Accuracy: 0.7438\n",
      "Epoch: 055, Loss: 0.3866, Val Accuracy: 0.7567, Test Accuracy: 0.7419\n",
      "Epoch: 056, Loss: 0.3853, Val Accuracy: 0.7567, Test Accuracy: 0.7448\n",
      "Epoch: 057, Loss: 0.3948, Val Accuracy: 0.7567, Test Accuracy: 0.7419\n",
      "Epoch: 058, Loss: 0.3891, Val Accuracy: 0.7605, Test Accuracy: 0.7353\n",
      "Epoch: 059, Loss: 0.3891, Val Accuracy: 0.7605, Test Accuracy: 0.7334\n",
      "Epoch: 060, Loss: 0.3916, Val Accuracy: 0.7586, Test Accuracy: 0.7372\n",
      "Epoch: 061, Loss: 0.3890, Val Accuracy: 0.7529, Test Accuracy: 0.7343\n",
      "Epoch: 062, Loss: 0.3893, Val Accuracy: 0.7548, Test Accuracy: 0.7429\n",
      "Epoch: 063, Loss: 0.3886, Val Accuracy: 0.7586, Test Accuracy: 0.7410\n",
      "Epoch: 064, Loss: 0.3883, Val Accuracy: 0.7567, Test Accuracy: 0.7410\n",
      "Epoch: 065, Loss: 0.3929, Val Accuracy: 0.7624, Test Accuracy: 0.7381\n",
      "Epoch: 066, Loss: 0.3952, Val Accuracy: 0.7490, Test Accuracy: 0.7353\n",
      "Epoch: 067, Loss: 0.3846, Val Accuracy: 0.7490, Test Accuracy: 0.7391\n",
      "Epoch: 068, Loss: 0.3908, Val Accuracy: 0.7605, Test Accuracy: 0.7400\n",
      "Epoch: 069, Loss: 0.3843, Val Accuracy: 0.7586, Test Accuracy: 0.7362\n",
      "Epoch: 070, Loss: 0.3860, Val Accuracy: 0.7586, Test Accuracy: 0.7381\n",
      "Epoch: 071, Loss: 0.3854, Val Accuracy: 0.7605, Test Accuracy: 0.7372\n",
      "Epoch: 072, Loss: 0.3918, Val Accuracy: 0.7567, Test Accuracy: 0.7400\n",
      "Epoch: 073, Loss: 0.3914, Val Accuracy: 0.7605, Test Accuracy: 0.7400\n",
      "Epoch: 074, Loss: 0.3846, Val Accuracy: 0.7586, Test Accuracy: 0.7362\n",
      "Epoch: 075, Loss: 0.3856, Val Accuracy: 0.7681, Test Accuracy: 0.7362\n",
      "Epoch: 076, Loss: 0.3848, Val Accuracy: 0.7700, Test Accuracy: 0.7400\n",
      "Epoch: 077, Loss: 0.3905, Val Accuracy: 0.7643, Test Accuracy: 0.7391\n",
      "Epoch: 078, Loss: 0.3915, Val Accuracy: 0.7605, Test Accuracy: 0.7381\n",
      "Epoch: 079, Loss: 0.3898, Val Accuracy: 0.7643, Test Accuracy: 0.7410\n",
      "Epoch: 080, Loss: 0.3834, Val Accuracy: 0.7605, Test Accuracy: 0.7438\n",
      "Epoch: 081, Loss: 0.3874, Val Accuracy: 0.7662, Test Accuracy: 0.7448\n",
      "Epoch: 082, Loss: 0.3831, Val Accuracy: 0.7624, Test Accuracy: 0.7419\n",
      "Epoch: 083, Loss: 0.3840, Val Accuracy: 0.7643, Test Accuracy: 0.7410\n",
      "Epoch: 084, Loss: 0.3851, Val Accuracy: 0.7662, Test Accuracy: 0.7438\n",
      "Epoch: 085, Loss: 0.3924, Val Accuracy: 0.7643, Test Accuracy: 0.7400\n",
      "Epoch: 086, Loss: 0.3966, Val Accuracy: 0.7624, Test Accuracy: 0.7400\n",
      "Epoch: 087, Loss: 0.3850, Val Accuracy: 0.7624, Test Accuracy: 0.7391\n",
      "Epoch: 088, Loss: 0.3860, Val Accuracy: 0.7662, Test Accuracy: 0.7410\n",
      "Epoch: 089, Loss: 0.3829, Val Accuracy: 0.7681, Test Accuracy: 0.7429\n",
      "Epoch: 090, Loss: 0.3908, Val Accuracy: 0.7700, Test Accuracy: 0.7391\n",
      "Epoch: 091, Loss: 0.3882, Val Accuracy: 0.7643, Test Accuracy: 0.7419\n",
      "Epoch: 092, Loss: 0.3928, Val Accuracy: 0.7700, Test Accuracy: 0.7438\n",
      "Epoch: 093, Loss: 0.3854, Val Accuracy: 0.7643, Test Accuracy: 0.7448\n",
      "Epoch: 094, Loss: 0.3858, Val Accuracy: 0.7605, Test Accuracy: 0.7457\n",
      "Epoch: 095, Loss: 0.3844, Val Accuracy: 0.7624, Test Accuracy: 0.7438\n",
      "Epoch: 096, Loss: 0.3858, Val Accuracy: 0.7719, Test Accuracy: 0.7438\n",
      "Epoch: 097, Loss: 0.3885, Val Accuracy: 0.7738, Test Accuracy: 0.7438\n",
      "Epoch: 098, Loss: 0.3809, Val Accuracy: 0.7719, Test Accuracy: 0.7457\n",
      "Epoch: 099, Loss: 0.3886, Val Accuracy: 0.7776, Test Accuracy: 0.7486\n",
      "Epoch: 100, Loss: 0.3876, Val Accuracy: 0.7757, Test Accuracy: 0.7467\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"624.398437pt\" height=\"340.723594pt\" viewBox=\"0 0 624.398437 340.723594\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-09-30T17:20:38.538191</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 340.723594 \n",
       "L 624.398437 340.723594 \n",
       "L 624.398437 -0 \n",
       "L -0 -0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 59.198438 298.989375 \n",
       "L 617.198437 298.989375 \n",
       "L 617.198437 21.789375 \n",
       "L 59.198438 21.789375 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 84.562074 298.989375 \n",
       "L 84.562074 21.789375 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(81.503558 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path d=\"M 187.041413 298.989375 \n",
       "L 187.041413 21.789375 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(180.924381 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 289.520752 298.989375 \n",
       "L 289.520752 21.789375 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(283.40372 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path d=\"M 392.00009 298.989375 \n",
       "L 392.00009 21.789375 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(385.883059 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 494.479429 298.989375 \n",
       "L 494.479429 21.789375 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(488.362398 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
       "Q 781 2613 612 2850 \n",
       "Q 444 3088 444 3419 \n",
       "Q 444 3919 803 4259 \n",
       "Q 1163 4600 1759 4600 \n",
       "Q 2359 4600 2725 4251 \n",
       "Q 3091 3903 3091 3403 \n",
       "Q 3091 3084 2923 2848 \n",
       "Q 2756 2613 2416 2484 \n",
       "Q 2838 2347 3058 2040 \n",
       "Q 3278 1734 3278 1309 \n",
       "Q 3278 722 2862 322 \n",
       "Q 2447 -78 1769 -78 \n",
       "Q 1091 -78 675 323 \n",
       "Q 259 725 259 1325 \n",
       "Q 259 1772 486 2073 \n",
       "Q 713 2375 1131 2484 \n",
       "z\n",
       "M 1019 3438 \n",
       "Q 1019 3113 1228 2906 \n",
       "Q 1438 2700 1772 2700 \n",
       "Q 2097 2700 2305 2904 \n",
       "Q 2513 3109 2513 3406 \n",
       "Q 2513 3716 2298 3927 \n",
       "Q 2084 4138 1766 4138 \n",
       "Q 1444 4138 1231 3931 \n",
       "Q 1019 3725 1019 3438 \n",
       "z\n",
       "M 838 1322 \n",
       "Q 838 1081 952 856 \n",
       "Q 1066 631 1291 507 \n",
       "Q 1516 384 1775 384 \n",
       "Q 2178 384 2440 643 \n",
       "Q 2703 903 2703 1303 \n",
       "Q 2703 1709 2433 1975 \n",
       "Q 2163 2241 1756 2241 \n",
       "Q 1359 2241 1098 1978 \n",
       "Q 838 1716 838 1322 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-38\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path d=\"M 596.958768 298.989375 \n",
       "L 596.958768 21.789375 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(587.783221 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epochs -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(318.186563 331.138594) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-45\" d=\"M 506 0 \n",
       "L 506 4581 \n",
       "L 3819 4581 \n",
       "L 3819 4041 \n",
       "L 1113 4041 \n",
       "L 1113 2638 \n",
       "L 3647 2638 \n",
       "L 3647 2100 \n",
       "L 1113 2100 \n",
       "L 1113 541 \n",
       "L 3925 541 \n",
       "L 3925 0 \n",
       "L 506 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
       "L 422 3319 \n",
       "L 934 3319 \n",
       "L 934 2888 \n",
       "Q 1116 3141 1344 3267 \n",
       "Q 1572 3394 1897 3394 \n",
       "Q 2322 3394 2647 3175 \n",
       "Q 2972 2956 3137 2557 \n",
       "Q 3303 2159 3303 1684 \n",
       "Q 3303 1175 3120 767 \n",
       "Q 2938 359 2589 142 \n",
       "Q 2241 -75 1856 -75 \n",
       "Q 1575 -75 1351 44 \n",
       "Q 1128 163 984 344 \n",
       "L 984 -1272 \n",
       "L 422 -1272 \n",
       "z\n",
       "M 931 1641 \n",
       "Q 931 1000 1190 694 \n",
       "Q 1450 388 1819 388 \n",
       "Q 2194 388 2461 705 \n",
       "Q 2728 1022 2728 1688 \n",
       "Q 2728 2322 2467 2637 \n",
       "Q 2206 2953 1844 2953 \n",
       "Q 1484 2953 1207 2617 \n",
       "Q 931 2281 931 1641 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6f\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-63\" d=\"M 2588 1216 \n",
       "L 3141 1144 \n",
       "Q 3050 572 2676 248 \n",
       "Q 2303 -75 1759 -75 \n",
       "Q 1078 -75 664 370 \n",
       "Q 250 816 250 1647 \n",
       "Q 250 2184 428 2587 \n",
       "Q 606 2991 970 3192 \n",
       "Q 1334 3394 1763 3394 \n",
       "Q 2303 3394 2647 3120 \n",
       "Q 2991 2847 3088 2344 \n",
       "L 2541 2259 \n",
       "Q 2463 2594 2264 2762 \n",
       "Q 2066 2931 1784 2931 \n",
       "Q 1359 2931 1093 2626 \n",
       "Q 828 2322 828 1663 \n",
       "Q 828 994 1084 691 \n",
       "Q 1341 388 1753 388 \n",
       "Q 2084 388 2306 591 \n",
       "Q 2528 794 2588 1216 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-68\" d=\"M 422 0 \n",
       "L 422 4581 \n",
       "L 984 4581 \n",
       "L 984 2938 \n",
       "Q 1378 3394 1978 3394 \n",
       "Q 2347 3394 2619 3248 \n",
       "Q 2891 3103 3008 2847 \n",
       "Q 3125 2591 3125 2103 \n",
       "L 3125 0 \n",
       "L 2563 0 \n",
       "L 2563 2103 \n",
       "Q 2563 2525 2380 2717 \n",
       "Q 2197 2909 1863 2909 \n",
       "Q 1613 2909 1392 2779 \n",
       "Q 1172 2650 1078 2428 \n",
       "Q 984 2206 984 1816 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-45\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" x=\"66.699219\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" x=\"122.314453\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"177.929688\"/>\n",
       "      <use xlink:href=\"#ArialMT-68\" x=\"227.929688\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"283.544922\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 59.198438 268.83866 \n",
       "L 617.198437 268.83866 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.382 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 272.775457) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-2e\" d=\"M 581 0 \n",
       "L 581 641 \n",
       "L 1222 641 \n",
       "L 1222 0 \n",
       "L 581 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
       "L 831 1284 \n",
       "Q 928 806 1161 595 \n",
       "Q 1394 384 1728 384 \n",
       "Q 2125 384 2398 659 \n",
       "Q 2672 934 2672 1341 \n",
       "Q 2672 1728 2419 1979 \n",
       "Q 2166 2231 1775 2231 \n",
       "Q 1616 2231 1378 2169 \n",
       "L 1441 2663 \n",
       "Q 1497 2656 1531 2656 \n",
       "Q 1891 2656 2178 2843 \n",
       "Q 2466 3031 2466 3422 \n",
       "Q 2466 3731 2256 3934 \n",
       "Q 2047 4138 1716 4138 \n",
       "Q 1388 4138 1169 3931 \n",
       "Q 950 3725 888 3313 \n",
       "L 325 3413 \n",
       "Q 428 3978 793 4289 \n",
       "Q 1159 4600 1703 4600 \n",
       "Q 2078 4600 2393 4439 \n",
       "Q 2709 4278 2876 4000 \n",
       "Q 3044 3722 3044 3409 \n",
       "Q 3044 3113 2884 2869 \n",
       "Q 2725 2625 2413 2481 \n",
       "Q 2819 2388 3044 2092 \n",
       "Q 3269 1797 3269 1353 \n",
       "Q 3269 753 2831 336 \n",
       "Q 2394 -81 1725 -81 \n",
       "Q 1122 -81 723 278 \n",
       "Q 325 638 269 1209 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"139.013672\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"194.628906\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path d=\"M 59.198438 236.632601 \n",
       "L 617.198437 236.632601 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.384 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 240.569398) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"139.013672\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" x=\"194.628906\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 59.198438 204.426542 \n",
       "L 617.198437 204.426542 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.386 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 208.363339) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"139.013672\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" x=\"194.628906\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path d=\"M 59.198438 172.220483 \n",
       "L 617.198437 172.220483 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.388 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 176.15728) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"139.013672\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"194.628906\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 59.198438 140.014424 \n",
       "L 617.198437 140.014424 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.390 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 143.951221) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-39\" d=\"M 350 1059 \n",
       "L 891 1109 \n",
       "Q 959 728 1153 556 \n",
       "Q 1347 384 1650 384 \n",
       "Q 1909 384 2104 503 \n",
       "Q 2300 622 2425 820 \n",
       "Q 2550 1019 2634 1356 \n",
       "Q 2719 1694 2719 2044 \n",
       "Q 2719 2081 2716 2156 \n",
       "Q 2547 1888 2255 1720 \n",
       "Q 1963 1553 1622 1553 \n",
       "Q 1053 1553 659 1965 \n",
       "Q 266 2378 266 3053 \n",
       "Q 266 3750 677 4175 \n",
       "Q 1088 4600 1706 4600 \n",
       "Q 2153 4600 2523 4359 \n",
       "Q 2894 4119 3086 3673 \n",
       "Q 3278 3228 3278 2384 \n",
       "Q 3278 1506 3087 986 \n",
       "Q 2897 466 2520 194 \n",
       "Q 2144 -78 1638 -78 \n",
       "Q 1100 -78 759 220 \n",
       "Q 419 519 350 1059 \n",
       "z\n",
       "M 2653 3081 \n",
       "Q 2653 3566 2395 3850 \n",
       "Q 2138 4134 1775 4134 \n",
       "Q 1400 4134 1122 3828 \n",
       "Q 844 3522 844 3034 \n",
       "Q 844 2597 1108 2323 \n",
       "Q 1372 2050 1759 2050 \n",
       "Q 2150 2050 2401 2323 \n",
       "Q 2653 2597 2653 3081 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-39\" x=\"139.013672\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"194.628906\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path d=\"M 59.198438 107.808365 \n",
       "L 617.198437 107.808365 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.392 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 111.745162) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-39\" x=\"139.013672\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"194.628906\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 59.198438 75.602307 \n",
       "L 617.198437 75.602307 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.394 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 79.539103) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-39\" x=\"139.013672\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" x=\"194.628906\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <path d=\"M 59.198438 43.396248 \n",
       "L 617.198437 43.396248 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.396 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 47.333045) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-39\" x=\"139.013672\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" x=\"194.628906\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Loss -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(15.789375 173.0625) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-4c\" d=\"M 469 0 \n",
       "L 469 4581 \n",
       "L 1075 4581 \n",
       "L 1075 541 \n",
       "L 3331 541 \n",
       "L 3331 0 \n",
       "L 469 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-4c\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" x=\"55.615234\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"111.230469\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"161.230469\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 84.562074 152.144321 \n",
       "L 89.686041 169.890347 \n",
       "L 94.810008 107.248958 \n",
       "L 99.933975 186.375176 \n",
       "L 105.057942 83.967197 \n",
       "L 110.181909 162.099526 \n",
       "L 115.305876 50.228248 \n",
       "L 120.429842 140.542073 \n",
       "L 125.553809 130.794668 \n",
       "L 130.677776 132.707101 \n",
       "L 135.801743 126.751926 \n",
       "L 140.92571 108.893122 \n",
       "L 146.049677 183.229861 \n",
       "L 151.173644 197.981743 \n",
       "L 156.297611 133.731224 \n",
       "L 161.421578 162.990235 \n",
       "L 166.545545 217.603728 \n",
       "L 171.669512 172.869614 \n",
       "L 176.793479 94.874059 \n",
       "L 181.917446 119.858052 \n",
       "L 187.041413 187.658929 \n",
       "L 192.16538 95.260864 \n",
       "L 197.289347 126.026786 \n",
       "L 202.413314 78.303807 \n",
       "L 207.53728 146.906129 \n",
       "L 212.661247 130.896409 \n",
       "L 217.785214 106.009837 \n",
       "L 222.909181 99.393349 \n",
       "L 228.033148 155.63373 \n",
       "L 233.157115 66.295077 \n",
       "L 238.281082 152.704853 \n",
       "L 243.405049 108.161263 \n",
       "L 248.529016 151.36927 \n",
       "L 253.652983 232.442473 \n",
       "L 258.77695 166.177781 \n",
       "L 263.900917 249.605891 \n",
       "L 269.024884 194.942968 \n",
       "L 274.148851 183.7544 \n",
       "L 279.272818 92.175538 \n",
       "L 284.396785 180.358573 \n",
       "L 289.520752 81.9751 \n",
       "L 294.644718 215.062137 \n",
       "L 299.768685 122.570971 \n",
       "L 304.892652 210.502054 \n",
       "L 310.016619 173.504052 \n",
       "L 315.140586 212.287311 \n",
       "L 320.264553 178.975479 \n",
       "L 325.38852 89.456861 \n",
       "L 330.512487 161.085961 \n",
       "L 335.636454 140.721559 \n",
       "L 340.760421 188.142676 \n",
       "L 345.884388 187.720837 \n",
       "L 351.008355 158.565006 \n",
       "L 356.132322 97.711273 \n",
       "L 361.256289 195.34753 \n",
       "L 366.380256 215.038622 \n",
       "L 371.504223 63.515932 \n",
       "L 376.62819 154.551058 \n",
       "L 381.752157 154.034198 \n",
       "L 386.876123 114.852615 \n",
       "L 392.00009 155.657725 \n",
       "L 397.124057 151.286246 \n",
       "L 402.248024 163.212912 \n",
       "L 407.371991 167.400106 \n",
       "L 412.495958 93.261569 \n",
       "L 417.619925 56.742035 \n",
       "L 422.743892 227.223477 \n",
       "L 427.867859 127.188162 \n",
       "L 432.991826 232.426636 \n",
       "L 438.115793 205.182278 \n",
       "L 443.23976 214.751637 \n",
       "L 448.363727 111.45247 \n",
       "L 453.487694 117.752218 \n",
       "L 458.611661 226.620713 \n",
       "L 463.735628 210.563962 \n",
       "L 468.859595 224.093999 \n",
       "L 473.983561 131.791437 \n",
       "L 479.107528 115.442902 \n",
       "L 484.231495 143.146052 \n",
       "L 489.355462 246.96448 \n",
       "L 494.479429 181.641846 \n",
       "L 499.603396 251.288928 \n",
       "L 504.727363 237.435913 \n",
       "L 509.85133 219.384665 \n",
       "L 514.975297 101.711304 \n",
       "L 520.099264 34.389375 \n",
       "L 525.223231 220.842625 \n",
       "L 530.347198 204.365475 \n",
       "L 535.471165 254.795133 \n",
       "L 540.595132 126.468301 \n",
       "L 545.719099 168.384397 \n",
       "L 550.843066 94.171474 \n",
       "L 555.967033 213.532671 \n",
       "L 561.090999 208.283921 \n",
       "L 566.214966 230.06789 \n",
       "L 571.338933 208.333831 \n",
       "L 576.4629 163.645309 \n",
       "L 581.586867 286.389375 \n",
       "L 586.710834 163.175959 \n",
       "L 591.834801 178.630906 \n",
       "\" clip-path=\"url(#p944404059a)\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 59.198438 298.989375 \n",
       "L 59.198438 21.789375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 617.198437 298.989375 \n",
       "L 617.198437 21.789375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 59.198438 298.989375 \n",
       "L 617.198437 298.989375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 59.198438 21.789375 \n",
       "L 617.198437 21.789375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- Loss over Epochs -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(290.50875 15.789375) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-76\" d=\"M 1344 0 \n",
       "L 81 3319 \n",
       "L 675 3319 \n",
       "L 1388 1331 \n",
       "Q 1503 1009 1600 663 \n",
       "Q 1675 925 1809 1294 \n",
       "L 2547 3319 \n",
       "L 3125 3319 \n",
       "L 1869 0 \n",
       "L 1344 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-4c\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"55.615234\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" x=\"111.230469\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" x=\"161.230469\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" x=\"211.230469\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"239.013672\"/>\n",
       "     <use xlink:href=\"#ArialMT-76\" x=\"294.628906\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" x=\"344.628906\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" x=\"400.244141\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" x=\"433.544922\"/>\n",
       "     <use xlink:href=\"#ArialMT-45\" x=\"461.328125\"/>\n",
       "     <use xlink:href=\"#ArialMT-70\" x=\"528.027344\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"583.642578\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" x=\"639.257812\"/>\n",
       "     <use xlink:href=\"#ArialMT-68\" x=\"689.257812\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" x=\"744.873047\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 523.361562 46.149219 \n",
       "L 609.498437 46.149219 \n",
       "Q 611.698437 46.149219 611.698437 43.949219 \n",
       "L 611.698437 29.489375 \n",
       "Q 611.698437 27.289375 609.498437 27.289375 \n",
       "L 523.361562 27.289375 \n",
       "Q 521.161562 27.289375 521.161562 29.489375 \n",
       "L 521.161562 43.949219 \n",
       "Q 521.161562 46.149219 523.361562 46.149219 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\">\n",
       "     <path d=\"M 525.561562 35.712969 \n",
       "L 536.561562 35.712969 \n",
       "L 547.561562 35.712969 \n",
       "\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- Train Loss -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(556.361562 39.562969) scale(0.11 -0.11)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-54\" d=\"M 1659 0 \n",
       "L 1659 4041 \n",
       "L 150 4041 \n",
       "L 150 4581 \n",
       "L 3781 4581 \n",
       "L 3781 4041 \n",
       "L 2266 4041 \n",
       "L 2266 0 \n",
       "L 1659 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-54\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" x=\"57.333984\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"90.634766\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" x=\"146.25\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" x=\"168.466797\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" x=\"224.082031\"/>\n",
       "      <use xlink:href=\"#ArialMT-4c\" x=\"251.865234\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" x=\"307.480469\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"363.095703\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"413.095703\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p944404059a\">\n",
       "   <rect x=\"59.198438\" y=\"21.789375\" width=\"558\" height=\"277.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"618.422031pt\" height=\"340.723594pt\" viewBox=\"0 0 618.422031 340.723594\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-09-30T17:20:38.815165</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 340.723594 \n",
       "L 618.422031 340.723594 \n",
       "L 618.422031 -0 \n",
       "L 0 -0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 53.222031 298.989375 \n",
       "L 611.222031 298.989375 \n",
       "L 611.222031 21.789375 \n",
       "L 53.222031 21.789375 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 78.585668 298.989375 \n",
       "L 78.585668 21.789375 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(75.527152 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path d=\"M 181.065006 298.989375 \n",
       "L 181.065006 21.789375 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(174.947975 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 283.544345 298.989375 \n",
       "L 283.544345 21.789375 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(277.427314 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path d=\"M 386.023684 298.989375 \n",
       "L 386.023684 21.789375 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(379.906653 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 488.503023 298.989375 \n",
       "L 488.503023 21.789375 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(482.385992 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
       "Q 781 2613 612 2850 \n",
       "Q 444 3088 444 3419 \n",
       "Q 444 3919 803 4259 \n",
       "Q 1163 4600 1759 4600 \n",
       "Q 2359 4600 2725 4251 \n",
       "Q 3091 3903 3091 3403 \n",
       "Q 3091 3084 2923 2848 \n",
       "Q 2756 2613 2416 2484 \n",
       "Q 2838 2347 3058 2040 \n",
       "Q 3278 1734 3278 1309 \n",
       "Q 3278 722 2862 322 \n",
       "Q 2447 -78 1769 -78 \n",
       "Q 1091 -78 675 323 \n",
       "Q 259 725 259 1325 \n",
       "Q 259 1772 486 2073 \n",
       "Q 713 2375 1131 2484 \n",
       "z\n",
       "M 1019 3438 \n",
       "Q 1019 3113 1228 2906 \n",
       "Q 1438 2700 1772 2700 \n",
       "Q 2097 2700 2305 2904 \n",
       "Q 2513 3109 2513 3406 \n",
       "Q 2513 3716 2298 3927 \n",
       "Q 2084 4138 1766 4138 \n",
       "Q 1444 4138 1231 3931 \n",
       "Q 1019 3725 1019 3438 \n",
       "z\n",
       "M 838 1322 \n",
       "Q 838 1081 952 856 \n",
       "Q 1066 631 1291 507 \n",
       "Q 1516 384 1775 384 \n",
       "Q 2178 384 2440 643 \n",
       "Q 2703 903 2703 1303 \n",
       "Q 2703 1709 2433 1975 \n",
       "Q 2163 2241 1756 2241 \n",
       "Q 1359 2241 1098 1978 \n",
       "Q 838 1716 838 1322 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-38\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path d=\"M 590.982362 298.989375 \n",
       "L 590.982362 21.789375 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(581.806815 316.362969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epochs -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(312.210156 331.138594) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-45\" d=\"M 506 0 \n",
       "L 506 4581 \n",
       "L 3819 4581 \n",
       "L 3819 4041 \n",
       "L 1113 4041 \n",
       "L 1113 2638 \n",
       "L 3647 2638 \n",
       "L 3647 2100 \n",
       "L 1113 2100 \n",
       "L 1113 541 \n",
       "L 3925 541 \n",
       "L 3925 0 \n",
       "L 506 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
       "L 422 3319 \n",
       "L 934 3319 \n",
       "L 934 2888 \n",
       "Q 1116 3141 1344 3267 \n",
       "Q 1572 3394 1897 3394 \n",
       "Q 2322 3394 2647 3175 \n",
       "Q 2972 2956 3137 2557 \n",
       "Q 3303 2159 3303 1684 \n",
       "Q 3303 1175 3120 767 \n",
       "Q 2938 359 2589 142 \n",
       "Q 2241 -75 1856 -75 \n",
       "Q 1575 -75 1351 44 \n",
       "Q 1128 163 984 344 \n",
       "L 984 -1272 \n",
       "L 422 -1272 \n",
       "z\n",
       "M 931 1641 \n",
       "Q 931 1000 1190 694 \n",
       "Q 1450 388 1819 388 \n",
       "Q 2194 388 2461 705 \n",
       "Q 2728 1022 2728 1688 \n",
       "Q 2728 2322 2467 2637 \n",
       "Q 2206 2953 1844 2953 \n",
       "Q 1484 2953 1207 2617 \n",
       "Q 931 2281 931 1641 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6f\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-63\" d=\"M 2588 1216 \n",
       "L 3141 1144 \n",
       "Q 3050 572 2676 248 \n",
       "Q 2303 -75 1759 -75 \n",
       "Q 1078 -75 664 370 \n",
       "Q 250 816 250 1647 \n",
       "Q 250 2184 428 2587 \n",
       "Q 606 2991 970 3192 \n",
       "Q 1334 3394 1763 3394 \n",
       "Q 2303 3394 2647 3120 \n",
       "Q 2991 2847 3088 2344 \n",
       "L 2541 2259 \n",
       "Q 2463 2594 2264 2762 \n",
       "Q 2066 2931 1784 2931 \n",
       "Q 1359 2931 1093 2626 \n",
       "Q 828 2322 828 1663 \n",
       "Q 828 994 1084 691 \n",
       "Q 1341 388 1753 388 \n",
       "Q 2084 388 2306 591 \n",
       "Q 2528 794 2588 1216 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-68\" d=\"M 422 0 \n",
       "L 422 4581 \n",
       "L 984 4581 \n",
       "L 984 2938 \n",
       "Q 1378 3394 1978 3394 \n",
       "Q 2347 3394 2619 3248 \n",
       "Q 2891 3103 3008 2847 \n",
       "Q 3125 2591 3125 2103 \n",
       "L 3125 0 \n",
       "L 2563 0 \n",
       "L 2563 2103 \n",
       "Q 2563 2525 2380 2717 \n",
       "Q 2197 2909 1863 2909 \n",
       "Q 1613 2909 1392 2779 \n",
       "Q 1172 2650 1078 2428 \n",
       "Q 984 2206 984 1816 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-45\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" x=\"66.699219\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" x=\"122.314453\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"177.929688\"/>\n",
       "      <use xlink:href=\"#ArialMT-68\" x=\"227.929688\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"283.544922\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 53.222031 257.782888 \n",
       "L 611.222031 257.782888 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.73 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.315 261.719685) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-2e\" d=\"M 581 0 \n",
       "L 581 641 \n",
       "L 1222 641 \n",
       "L 1222 0 \n",
       "L 581 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-37\" d=\"M 303 3981 \n",
       "L 303 4522 \n",
       "L 3269 4522 \n",
       "L 3269 4084 \n",
       "Q 2831 3619 2401 2847 \n",
       "Q 1972 2075 1738 1259 \n",
       "Q 1569 684 1522 0 \n",
       "L 944 0 \n",
       "Q 953 541 1156 1306 \n",
       "Q 1359 2072 1739 2783 \n",
       "Q 2119 3494 2547 3981 \n",
       "L 303 3981 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
       "L 831 1284 \n",
       "Q 928 806 1161 595 \n",
       "Q 1394 384 1728 384 \n",
       "Q 2125 384 2398 659 \n",
       "Q 2672 934 2672 1341 \n",
       "Q 2672 1728 2419 1979 \n",
       "Q 2166 2231 1775 2231 \n",
       "Q 1616 2231 1378 2169 \n",
       "L 1441 2663 \n",
       "Q 1497 2656 1531 2656 \n",
       "Q 1891 2656 2178 2843 \n",
       "Q 2466 3031 2466 3422 \n",
       "Q 2466 3731 2256 3934 \n",
       "Q 2047 4138 1716 4138 \n",
       "Q 1388 4138 1169 3931 \n",
       "Q 950 3725 888 3313 \n",
       "L 325 3413 \n",
       "Q 428 3978 793 4289 \n",
       "Q 1159 4600 1703 4600 \n",
       "Q 2078 4600 2393 4439 \n",
       "Q 2709 4278 2876 4000 \n",
       "Q 3044 3722 3044 3409 \n",
       "Q 3044 3113 2884 2869 \n",
       "Q 2725 2625 2413 2481 \n",
       "Q 2819 2388 3044 2092 \n",
       "Q 3269 1797 3269 1353 \n",
       "Q 3269 753 2831 336 \n",
       "Q 2394 -81 1725 -81 \n",
       "Q 1122 -81 723 278 \n",
       "Q 325 638 269 1209 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" x=\"139.013672\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path d=\"M 53.222031 210.818476 \n",
       "L 611.222031 210.818476 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.74 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.315 214.755273) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" x=\"139.013672\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 53.222031 163.854065 \n",
       "L 611.222031 163.854065 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.75 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.315 167.790862) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
       "L 856 1250 \n",
       "Q 922 819 1161 601 \n",
       "Q 1400 384 1738 384 \n",
       "Q 2144 384 2425 690 \n",
       "Q 2706 997 2706 1503 \n",
       "Q 2706 1984 2436 2262 \n",
       "Q 2166 2541 1728 2541 \n",
       "Q 1456 2541 1237 2417 \n",
       "Q 1019 2294 894 2097 \n",
       "L 366 2166 \n",
       "L 809 4519 \n",
       "L 3088 4519 \n",
       "L 3088 3981 \n",
       "L 1259 3981 \n",
       "L 1013 2750 \n",
       "Q 1425 3038 1878 3038 \n",
       "Q 2478 3038 2890 2622 \n",
       "Q 3303 2206 3303 1553 \n",
       "Q 3303 931 2941 478 \n",
       "Q 2500 -78 1738 -78 \n",
       "Q 1113 -78 717 272 \n",
       "Q 322 622 266 1200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"139.013672\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path d=\"M 53.222031 116.889653 \n",
       "L 611.222031 116.889653 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.76 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.315 120.82645) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" x=\"139.013672\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 53.222031 69.925242 \n",
       "L 611.222031 69.925242 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.77 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.315 73.862039) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" x=\"139.013672\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path d=\"M 53.222031 22.96083 \n",
       "L 611.222031 22.96083 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.78 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.315 26.897627) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" x=\"83.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"139.013672\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- Accuracy -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(15.789375 185.0625) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-41\" d=\"M -9 0 \n",
       "L 1750 4581 \n",
       "L 2403 4581 \n",
       "L 4278 0 \n",
       "L 3588 0 \n",
       "L 3053 1388 \n",
       "L 1138 1388 \n",
       "L 634 0 \n",
       "L -9 0 \n",
       "z\n",
       "M 1313 1881 \n",
       "L 2866 1881 \n",
       "L 2388 3150 \n",
       "Q 2169 3728 2063 4100 \n",
       "Q 1975 3659 1816 3225 \n",
       "L 1313 1881 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-75\" d=\"M 2597 0 \n",
       "L 2597 488 \n",
       "Q 2209 -75 1544 -75 \n",
       "Q 1250 -75 995 37 \n",
       "Q 741 150 617 320 \n",
       "Q 494 491 444 738 \n",
       "Q 409 903 409 1263 \n",
       "L 409 3319 \n",
       "L 972 3319 \n",
       "L 972 1478 \n",
       "Q 972 1038 1006 884 \n",
       "Q 1059 663 1231 536 \n",
       "Q 1403 409 1656 409 \n",
       "Q 1909 409 2131 539 \n",
       "Q 2353 669 2445 892 \n",
       "Q 2538 1116 2538 1541 \n",
       "L 2538 3319 \n",
       "L 3100 3319 \n",
       "L 3100 0 \n",
       "L 2597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-79\" d=\"M 397 -1278 \n",
       "L 334 -750 \n",
       "Q 519 -800 656 -800 \n",
       "Q 844 -800 956 -737 \n",
       "Q 1069 -675 1141 -563 \n",
       "Q 1194 -478 1313 -144 \n",
       "Q 1328 -97 1363 -6 \n",
       "L 103 3319 \n",
       "L 709 3319 \n",
       "L 1400 1397 \n",
       "Q 1534 1031 1641 628 \n",
       "Q 1738 1016 1872 1384 \n",
       "L 2581 3319 \n",
       "L 3144 3319 \n",
       "L 1881 -56 \n",
       "Q 1678 -603 1566 -809 \n",
       "Q 1416 -1088 1222 -1217 \n",
       "Q 1028 -1347 759 -1347 \n",
       "Q 597 -1347 397 -1278 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-41\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"66.699219\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"116.699219\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" x=\"166.699219\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" x=\"222.314453\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"255.615234\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"311.230469\"/>\n",
       "      <use xlink:href=\"#ArialMT-79\" x=\"361.230469\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 78.585668 52.246651 \n",
       "L 83.709635 87.960923 \n",
       "L 88.833601 105.818198 \n",
       "L 93.957568 114.746836 \n",
       "L 99.081535 79.032285 \n",
       "L 104.205502 70.103927 \n",
       "L 109.329469 87.960923 \n",
       "L 114.453436 61.175289 \n",
       "L 119.577403 105.818198 \n",
       "L 124.70137 87.960923 \n",
       "L 129.825337 96.889561 \n",
       "L 134.949304 105.818198 \n",
       "L 140.073271 96.889561 \n",
       "L 145.197238 87.960923 \n",
       "L 150.321205 132.604112 \n",
       "L 155.445172 177.247022 \n",
       "L 160.569139 150.461108 \n",
       "L 165.693106 79.032285 \n",
       "L 170.817073 114.746836 \n",
       "L 175.94104 132.604112 \n",
       "L 181.065006 132.604112 \n",
       "L 186.188973 150.461108 \n",
       "L 191.31294 132.604112 \n",
       "L 196.436907 141.53247 \n",
       "L 201.560874 141.53247 \n",
       "L 206.684841 123.675474 \n",
       "L 211.808808 123.675474 \n",
       "L 216.932775 123.675474 \n",
       "L 222.056742 141.53247 \n",
       "L 227.180709 141.53247 \n",
       "L 232.304676 123.675474 \n",
       "L 237.428643 96.889561 \n",
       "L 242.55261 105.818198 \n",
       "L 247.676577 87.960923 \n",
       "L 252.800544 96.889561 \n",
       "L 257.924511 70.103927 \n",
       "L 263.048478 105.818198 \n",
       "L 268.172444 79.032285 \n",
       "L 273.296411 105.818198 \n",
       "L 278.420378 114.746836 \n",
       "L 283.544345 123.675474 \n",
       "L 288.668312 114.746836 \n",
       "L 293.792279 123.675474 \n",
       "L 298.916246 150.461108 \n",
       "L 304.040213 150.461108 \n",
       "L 309.16418 141.53247 \n",
       "L 314.288147 141.53247 \n",
       "L 319.412114 132.604112 \n",
       "L 324.536081 186.17566 \n",
       "L 329.660048 186.17566 \n",
       "L 334.784015 168.318384 \n",
       "L 339.907982 132.604112 \n",
       "L 345.031949 114.746836 \n",
       "L 350.155916 114.746836 \n",
       "L 355.279882 132.604112 \n",
       "L 360.403849 132.604112 \n",
       "L 365.527816 132.604112 \n",
       "L 370.651783 114.746836 \n",
       "L 375.77575 114.746836 \n",
       "L 380.899717 123.675474 \n",
       "L 386.023684 150.461108 \n",
       "L 391.147651 141.53247 \n",
       "L 396.271618 123.675474 \n",
       "L 401.395585 132.604112 \n",
       "L 406.519552 105.818198 \n",
       "L 411.643519 168.318384 \n",
       "L 416.767486 168.318384 \n",
       "L 421.891453 114.746836 \n",
       "L 427.01542 123.675474 \n",
       "L 432.139387 123.675474 \n",
       "L 437.263354 114.746836 \n",
       "L 442.387321 132.604112 \n",
       "L 447.511287 114.746836 \n",
       "L 452.635254 123.675474 \n",
       "L 457.759221 79.032285 \n",
       "L 462.883188 70.103927 \n",
       "L 468.007155 96.889561 \n",
       "L 473.131122 114.746836 \n",
       "L 478.255089 96.889561 \n",
       "L 483.379056 114.746836 \n",
       "L 488.503023 87.960923 \n",
       "L 493.62699 105.818198 \n",
       "L 498.750957 96.889561 \n",
       "L 503.874924 87.960923 \n",
       "L 508.998891 96.889561 \n",
       "L 514.122858 105.818198 \n",
       "L 519.246825 105.818198 \n",
       "L 524.370792 87.960923 \n",
       "L 529.494759 79.032285 \n",
       "L 534.618725 70.103927 \n",
       "L 539.742692 96.889561 \n",
       "L 544.866659 70.103927 \n",
       "L 549.990626 96.889561 \n",
       "L 555.114593 114.746836 \n",
       "L 560.23856 105.818198 \n",
       "L 565.362527 61.175289 \n",
       "L 570.486494 52.246651 \n",
       "L 575.610461 61.175289 \n",
       "L 580.734428 34.389375 \n",
       "L 585.858395 43.318013 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 78.585668 219.551959 \n",
       "L 83.709635 219.551959 \n",
       "L 88.833601 179.449509 \n",
       "L 93.957568 188.361071 \n",
       "L 99.081535 197.272633 \n",
       "L 104.205502 237.375083 \n",
       "L 109.329469 241.831004 \n",
       "L 114.453436 232.919442 \n",
       "L 119.577403 219.551959 \n",
       "L 124.70137 228.463521 \n",
       "L 129.825337 224.0076 \n",
       "L 134.949304 224.0076 \n",
       "L 140.073271 219.551959 \n",
       "L 145.197238 206.184475 \n",
       "L 150.321205 215.096038 \n",
       "L 155.445172 228.463521 \n",
       "L 160.569139 201.728554 \n",
       "L 165.693106 174.993588 \n",
       "L 170.817073 219.551959 \n",
       "L 175.94104 219.551959 \n",
       "L 181.065006 246.286925 \n",
       "L 186.188973 224.0076 \n",
       "L 191.31294 197.272633 \n",
       "L 196.436907 228.463521 \n",
       "L 201.560874 250.742566 \n",
       "L 206.684841 215.096038 \n",
       "L 211.808808 228.463521 \n",
       "L 216.932775 232.919442 \n",
       "L 222.056742 273.021892 \n",
       "L 227.180709 286.389375 \n",
       "L 232.304676 250.742566 \n",
       "L 237.428643 237.375083 \n",
       "L 242.55261 228.463521 \n",
       "L 247.676577 255.198487 \n",
       "L 252.800544 232.919442 \n",
       "L 257.924511 255.198487 \n",
       "L 263.048478 237.375083 \n",
       "L 268.172444 232.919442 \n",
       "L 273.296411 232.919442 \n",
       "L 278.420378 228.463521 \n",
       "L 283.544345 215.096038 \n",
       "L 288.668312 201.728554 \n",
       "L 293.792279 215.096038 \n",
       "L 298.916246 192.816992 \n",
       "L 304.040213 192.816992 \n",
       "L 309.16418 192.816992 \n",
       "L 314.288147 206.184475 \n",
       "L 319.412114 188.361071 \n",
       "L 324.536081 188.361071 \n",
       "L 329.660048 206.184475 \n",
       "L 334.784015 224.0076 \n",
       "L 339.907982 206.184475 \n",
       "L 345.031949 210.640116 \n",
       "L 350.155916 192.816992 \n",
       "L 355.279882 201.728554 \n",
       "L 360.403849 188.361071 \n",
       "L 365.527816 201.728554 \n",
       "L 370.651783 232.919442 \n",
       "L 375.77575 241.831004 \n",
       "L 380.899717 224.0076 \n",
       "L 386.023684 237.375083 \n",
       "L 391.147651 197.272633 \n",
       "L 396.271618 206.184475 \n",
       "L 401.395585 206.184475 \n",
       "L 406.519552 219.551959 \n",
       "L 411.643519 232.919442 \n",
       "L 416.767486 215.096038 \n",
       "L 421.891453 210.640116 \n",
       "L 427.01542 228.463521 \n",
       "L 432.139387 219.551959 \n",
       "L 437.263354 224.0076 \n",
       "L 442.387321 210.640116 \n",
       "L 447.511287 210.640116 \n",
       "L 452.635254 228.463521 \n",
       "L 457.759221 228.463521 \n",
       "L 462.883188 210.640116 \n",
       "L 468.007155 215.096038 \n",
       "L 473.131122 219.551959 \n",
       "L 478.255089 206.184475 \n",
       "L 483.379056 192.816992 \n",
       "L 488.503023 188.361071 \n",
       "L 493.62699 201.728554 \n",
       "L 498.750957 206.184475 \n",
       "L 503.874924 192.816992 \n",
       "L 508.998891 210.640116 \n",
       "L 514.122858 210.640116 \n",
       "L 519.246825 215.096038 \n",
       "L 524.370792 206.184475 \n",
       "L 529.494759 197.272633 \n",
       "L 534.618725 215.096038 \n",
       "L 539.742692 201.728554 \n",
       "L 544.866659 192.816992 \n",
       "L 549.990626 188.361071 \n",
       "L 555.114593 183.90515 \n",
       "L 560.23856 192.816992 \n",
       "L 565.362527 192.816992 \n",
       "L 570.486494 192.816992 \n",
       "L 575.610461 183.90515 \n",
       "L 580.734428 170.537667 \n",
       "L 585.858395 179.449509 \n",
       "\" clip-path=\"url(#p653d418388)\" style=\"fill: none; stroke: #dd8452; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 53.222031 298.989375 \n",
       "L 53.222031 21.789375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 611.222031 298.989375 \n",
       "L 611.222031 21.789375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 53.222031 298.989375 \n",
       "L 611.222031 298.989375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 53.222031 21.789375 \n",
       "L 611.222031 21.789375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- Accuracy over Epochs -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(272.532344 15.789375) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-76\" d=\"M 1344 0 \n",
       "L 81 3319 \n",
       "L 675 3319 \n",
       "L 1388 1331 \n",
       "Q 1503 1009 1600 663 \n",
       "Q 1675 925 1809 1294 \n",
       "L 2547 3319 \n",
       "L 3125 3319 \n",
       "L 1869 0 \n",
       "L 1344 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-41\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" x=\"66.699219\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" x=\"116.699219\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" x=\"166.699219\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" x=\"222.314453\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" x=\"255.615234\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" x=\"311.230469\"/>\n",
       "     <use xlink:href=\"#ArialMT-79\" x=\"361.230469\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" x=\"411.230469\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"439.013672\"/>\n",
       "     <use xlink:href=\"#ArialMT-76\" x=\"494.628906\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" x=\"544.628906\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" x=\"600.244141\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" x=\"633.544922\"/>\n",
       "     <use xlink:href=\"#ArialMT-45\" x=\"661.328125\"/>\n",
       "     <use xlink:href=\"#ArialMT-70\" x=\"728.027344\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" x=\"783.642578\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" x=\"839.257812\"/>\n",
       "     <use xlink:href=\"#ArialMT-68\" x=\"889.257812\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" x=\"944.873047\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 60.922031 293.489375 \n",
       "L 191.306406 293.489375 \n",
       "Q 193.506406 293.489375 193.506406 291.289375 \n",
       "L 193.506406 261.011875 \n",
       "Q 193.506406 258.811875 191.306406 258.811875 \n",
       "L 60.922031 258.811875 \n",
       "Q 58.722031 258.811875 58.722031 261.011875 \n",
       "L 58.722031 291.289375 \n",
       "Q 58.722031 293.489375 60.922031 293.489375 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_15\">\n",
       "     <path d=\"M 63.122031 267.235469 \n",
       "L 74.122031 267.235469 \n",
       "L 85.122031 267.235469 \n",
       "\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Validation Accuracy -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(93.922031 271.085469) scale(0.11 -0.11)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-56\" d=\"M 1803 0 \n",
       "L 28 4581 \n",
       "L 684 4581 \n",
       "L 1875 1253 \n",
       "Q 2019 853 2116 503 \n",
       "Q 2222 878 2363 1253 \n",
       "L 3600 4581 \n",
       "L 4219 4581 \n",
       "L 2425 0 \n",
       "L 1803 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
       "L 409 4581 \n",
       "L 972 4581 \n",
       "L 972 0 \n",
       "L 409 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-64\" d=\"M 2575 0 \n",
       "L 2575 419 \n",
       "Q 2259 -75 1647 -75 \n",
       "Q 1250 -75 917 144 \n",
       "Q 584 363 401 755 \n",
       "Q 219 1147 219 1656 \n",
       "Q 219 2153 384 2558 \n",
       "Q 550 2963 881 3178 \n",
       "Q 1213 3394 1622 3394 \n",
       "Q 1922 3394 2156 3267 \n",
       "Q 2391 3141 2538 2938 \n",
       "L 2538 4581 \n",
       "L 3097 4581 \n",
       "L 3097 0 \n",
       "L 2575 0 \n",
       "z\n",
       "M 797 1656 \n",
       "Q 797 1019 1065 703 \n",
       "Q 1334 388 1700 388 \n",
       "Q 2069 388 2326 689 \n",
       "Q 2584 991 2584 1609 \n",
       "Q 2584 2291 2321 2609 \n",
       "Q 2059 2928 1675 2928 \n",
       "Q 1300 2928 1048 2622 \n",
       "Q 797 2316 797 1656 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-74\" d=\"M 1650 503 \n",
       "L 1731 6 \n",
       "Q 1494 -44 1306 -44 \n",
       "Q 1000 -44 831 53 \n",
       "Q 663 150 594 308 \n",
       "Q 525 466 525 972 \n",
       "L 525 2881 \n",
       "L 113 2881 \n",
       "L 113 3319 \n",
       "L 525 3319 \n",
       "L 525 4141 \n",
       "L 1084 4478 \n",
       "L 1084 3319 \n",
       "L 1650 3319 \n",
       "L 1650 2881 \n",
       "L 1084 2881 \n",
       "L 1084 941 \n",
       "Q 1084 700 1114 631 \n",
       "Q 1144 563 1211 522 \n",
       "Q 1278 481 1403 481 \n",
       "Q 1497 481 1650 503 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-56\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"59.324219\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" x=\"114.939453\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" x=\"137.15625\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" x=\"159.373047\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"214.988281\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" x=\"270.603516\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" x=\"298.386719\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" x=\"320.603516\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" x=\"376.21875\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" x=\"431.833984\"/>\n",
       "      <use xlink:href=\"#ArialMT-41\" x=\"454.117188\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"520.816406\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"570.816406\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" x=\"620.816406\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" x=\"676.431641\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"709.732422\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"765.347656\"/>\n",
       "      <use xlink:href=\"#ArialMT-79\" x=\"815.347656\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\">\n",
       "     <path d=\"M 63.122031 282.924219 \n",
       "L 74.122031 282.924219 \n",
       "L 85.122031 282.924219 \n",
       "\" style=\"fill: none; stroke: #dd8452; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- Test Accuracy -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(93.922031 286.774219) scale(0.11 -0.11)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-54\" d=\"M 1659 0 \n",
       "L 1659 4041 \n",
       "L 150 4041 \n",
       "L 150 4581 \n",
       "L 3781 4581 \n",
       "L 3781 4041 \n",
       "L 2266 4041 \n",
       "L 2266 0 \n",
       "L 1659 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-54\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" x=\"49.958984\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"105.574219\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" x=\"155.574219\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" x=\"183.357422\"/>\n",
       "      <use xlink:href=\"#ArialMT-41\" x=\"205.640625\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"272.339844\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"322.339844\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" x=\"372.339844\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" x=\"427.955078\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"461.255859\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" x=\"516.871094\"/>\n",
       "      <use xlink:href=\"#ArialMT-79\" x=\"566.871094\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p653d418388\">\n",
       "   <rect x=\"53.222031\" y=\"21.789375\" width=\"558\" height=\"277.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Se utiliza para desactivar el cálculo de gradientes\n",
    "@torch.no_grad()\n",
    "def test_accuracy(data):\n",
    "    # Pone el modelo en modo de evaluación\n",
    "    model.eval()\n",
    "    # Calcula las representaciones codificadas de los nodos del grafo utilizando el método encode del modelo.\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    #Decodifica las representaciones de los nodos para obtener las predicciones del modelo, aplica la función sigmoid para obtener probabilidades y reformatea el tensor resultante.\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    #Decodifica las representaciones de los nodos para obtener las predicciones del modelo, aplica la función sigmoid para obtener probabilidades y reformatea el tensor resultante.\n",
    "    predictions = (out > 0.5).float() # Convertir probabilidades a etiquetas binarias\n",
    "    # Calcula el número de predicciones correctas comparando las predicciones con las etiquetas verdaderas.\n",
    "    correct = (predictions == data.edge_label).float().sum()\n",
    "    # Calcula la precisión (accuracy) como el número de predicciones correctas dividido por el número total de etiquetas.\n",
    "    accuracy = correct / len(data.edge_label)\n",
    "    \n",
    "    return accuracy.item()\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    val_accuracy_score = test_accuracy(val_data)\n",
    "    val_accuracies.append(val_accuracy_score)\n",
    "    \n",
    "    test_accuracy_score = test_accuracy(test_data)\n",
    "    test_accuracies.append(test_accuracy_score)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Accuracy: {val_accuracy_score:.4f}, Test Accuracy: {test_accuracy_score:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficar la pérdida\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(losses, label='Train Loss')\n",
    "plt.title('Loss a lo largo de Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Graficar las precisiones\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.title('Accuracy a lo largo de Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSInVvkfo0D-"
   },
   "source": [
    "### A nivel de grafo (graph-level tasks). Ejemplo: Clasificación de moléculas\n",
    "\n",
    "Por último, vamos a aplicar las GNN a una clasificación a nivel de grafos. El objetivo es clasificar un grafo entero en lugar de nodos o aristas individuales. Por ejemplo, imaginemos que queremos comparar si una red de recomendaciones es muy parecida a la de otro cliente, para clasificarlos como similares de cara a futuras recomendaciones.\n",
    "\n",
    "Como ejemplo práctico, vamos a usar un dataset con múltiples grafos que tenemos que clasificar en base a algunas propiedades estructurales del grafo. Lo más típico es la predicción de propiedades moleculares, en la que las moléculas se representan como grafos. Cada átomo está vinculado a un nodo, y las aristas del grafo son los enlaces entre átomos. Podemos ver el ejemplo en la figura:\n",
    "\n",
    "\n",
    "<center width=\"100%\"><img src=\"https://phlippe.github.io/post/categorical-nf/molecule_graph.svg\" width=\"600px\"></center>\n",
    "\n",
    "A la izquierda, tenemos una pequeña molécula con diferentes átomos, mientras que la parte derecha de la imagen muestra la representación en forma de grafo. Los tipos de átomo se abstraen como características de nodo (por ejemplo, un vector de un punto), y los diferentes tipos de enlace se utilizan como características de la arista. Por simplicidad,no vamos a tener en cuenta los atributos de las aristas, pero se pueden incluir con métodos como la Convolución Relacional de Grafos (Relational Graph Convolution) que utiliza una matriz de pesos diferente para cada tipo de borde.\n",
    "\n",
    "\n",
    "El dataset a usar se llama [MUTAG](https://paperswithcode.com/dataset/mutag). Es una colección de compuestos nitroaromáticos y el objetivo es predecir su mutagenicidad en Salmonella typhimurium. Contiene 188 compuestos químicos/grafos con 18 nodos y 20 aristas de media para cada grafo. Los nodos del grafo tienen 7 etiquetas/tipos de átomo diferentes, y las etiquetas binarias del grafo representan \"su efecto mutagénico en una bacteria gramnegativa específica\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzVCHtCeo0D-",
    "outputId": "195362f3-04b5-4f68-fc29-22b2b0cb402e"
   },
   "outputs": [],
   "source": [
    "mutag_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"MUTAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8VnZPCWo0D_"
   },
   "source": [
    "Vemos algunas estadísticas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8x_9T6Kao0D_",
    "outputId": "987384ec-9faf-4acf-b454-87a654ae5199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato de los datos: Data(x=[3371, 7], edge_index=[2, 7442], edge_attr=[7442, 4], y=[188])\n",
      "Número de grafos: 188\n",
      "Etiqueta media: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "print(\"Formato de los datos:\", mutag_dataset.data)\n",
    "print(\"Número de grafos:\", len(mutag_dataset))\n",
    "print(f\"Etiqueta media: {mutag_dataset.data.y.float().mean().item():4.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PC3LhHCzo0D_"
   },
   "source": [
    "La primera línea muestra cómo el conjunto de datos almacena los distintos grafos en un tensor, con la concatenación de los nodos, las aristas y las etiquetas de cada grafo, así los índices en los que se dividen los tensores.\n",
    "\n",
    "La longitud del conjunto de datos es el número de grafos que tenemos, y la \"etiqueta media\" denota el porcentaje del grafo con etiqueta 1. Mientras el porcentaje esté en el intervalo de 0,5, tendremos un conjunto de datos relativamente equilibrado. Es una práctica muy recomendada, puesto que, a menudo, los conjuntos de datos de grafos están muy desequilibrados.\n",
    "\n",
    "Ahora vamos a dividir nuestro conjunto de datos en una parte de entrenamiento y otra de prueba. Tenga en cuenta que esta vez no utilizamos un conjunto de validación debido al pequeño tamaño del conjunto de datos. Por lo tanto, nuestro modelo podría sobreajustarse ligeramente en el conjunto de validación debido al ruido de la evaluación, pero aún así obtendremos una estimación del rendimiento en datos no entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "JOyvoK1so0D_"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "mutag_dataset.shuffle()\n",
    "train_dataset = mutag_dataset[:150]\n",
    "test_dataset = mutag_dataset[150:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG0qUJsQo0EA"
   },
   "source": [
    "Cuando usamos un data loader, nos encontramos con un problema al agrupar $N$ grafos por lotes. Cada grafo del lote puede tener un número diferente de nodos y aristas, por lo que necesitaríamos mucho relleno para obtener un único tensor.\n",
    "\n",
    "Torch geometric utiliza un enfoque diferente y más eficiente: podemos ver los grafos $N$ de un lote como un único grafo grande con una lista concatenada de nodos y aristas. Como no hay aristas entre los grafos $N$, ejecutar capas GNN en el grafo grande nos da el mismo resultado que ejecutar el GNN en cada grafo por separado (ver imagen abajo).\n",
    "\n",
    "\n",
    "<center width=\"100%\"><img src=\"https://theaisummer.com/static/4e7a74f1f1559f684294e111b7742d11/105d8/graph-batching.png\" width=\"600px\"></center>\n",
    "\n",
    "La matriz de adyacencia es cero para los nodos que proceden de dos grafos diferentes y, en caso contrario, según la matriz de adyacencia del grafo individual. Por suerte, esta estrategia ya está implementada en torch geometric, por lo que podemos usar el data loader correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tjpgq4LDo0EA",
    "outputId": "32422a5e-9b10-4d0b-ad30-decded009317"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=64, shuffle=True) #Shuffle = organizar en cada época\n",
    "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=64)\n",
    "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1TrGL2Co0EA"
   },
   "source": [
    "Carguemos un lote a continuación para ver la agrupación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRVnCBIco0EA",
    "outputId": "44c1d92a-9f49-49d2-e7e6-02c9353cb623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: DataBatch(edge_index=[2, 1512], x=[687, 7], edge_attr=[1512, 4], y=[38], batch=[687], ptr=[39])\n",
      "Etiquetas: tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
      "Índices del batch: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(graph_test_loader))\n",
    "print(\"Batch:\", batch)\n",
    "print(\"Etiquetas:\", batch.y[:10])\n",
    "print(\"Índices del batch:\", batch.batch[:40]) #Visualizamos solo las 40 primeras, para entenderlo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYL8Xtl1o0EB"
   },
   "source": [
    "Tenemos 38 grafos agrupados juntos para el conjunto de datos de test. Los índices de lote, almacenados en `batch`, muestran que los 12 primeros nodos pertenecen al primer grafo, los 22 siguientes al segundo, y así sucesivamente. Estos índices son importantes para realizar la predicción final. Para realizar una predicción sobre un grafo completo, normalmente realizamos una operación de agrupación sobre todos los nodos después de ejecutar el modelo GNN. En este caso, utilizaremos el average pooling. Por lo tanto, necesitamos saber qué nodos deben incluirse en cada average pool. Usando este pooling, ya podemos crear nuestra red de abajo. Concretamente, reutilizamos nuestra clase `GNNModel` de antes, y simplemente añadimos un average pooling y una única capa lineal para la tarea de predicción de grafos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "r28ct0ovo0EB"
   },
   "outputs": [],
   "source": [
    "class GraphGNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        Entradas:\n",
    "            c_in - Dimensionalidad de las características de entrada\n",
    "            c_hidden - Dimensionalidad de las características de la oculta\n",
    "            c_out - Dimensionalidad de las características de entrada (normalmente el número de clases)\n",
    "            dp_rate_linear - La tasa de dropout antes de la capa lineal (normalmente mucho mayor que dentro de la GNN)\n",
    "            kwargs - Argumentos adicionales para la GNN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.GNN = GNNModel(c_in=c_in,\n",
    "                            c_hidden=c_hidden,\n",
    "                            c_out=c_hidden, #No sería la predicción final todavia\n",
    "                            **kwargs)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(dp_rate_linear),\n",
    "            nn.Linear(c_hidden, c_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx):\n",
    "        \"\"\"\n",
    "        Entradas:\n",
    "            x - Características de entrada por nodo\n",
    "            edge_index - Lista de índices de los nodos que estan conectados por aristas en el grafo (notación de PyTorch geometric)\n",
    "            batch_idx - Índice del lote para cada nodo\n",
    "        \"\"\"\n",
    "        x = self.GNN(x, edge_index)\n",
    "        x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39MBUQoXo0EB"
   },
   "source": [
    "Por último, podemos crear un módulo PyTorch Lightning para manejar el entrenamiento, como ya explicamos antes. Como tenemos una tarea de clasificación binaria, usamos la función de pérdida Binary Cross Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "GcyPo_FKo0EB"
   },
   "outputs": [],
   "source": [
    "class GraphLevelGNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Guardando los hiperparámetros\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = GraphGNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss() #Función de pérdida\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "\n",
    "        if self.hparams.c_out == 1:\n",
    "            preds = (x > 0).float()\n",
    "            data.y = data.y.float()\n",
    "        else:\n",
    "            preds = x.argmax(dim=-1)\n",
    "        loss = self.loss_module(x, data.y)\n",
    "        acc = (preds == data.y).sum().float() / preds.shape[0]\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0) #Se pone una tasa de aprendizaje (lr) alto porque el dataset es pequeño (y el modelo)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.forward(batch, mode=\"train\")\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"val\")\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"test\")\n",
    "        self.log('test_acc', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc_c2wRBo0EC"
   },
   "source": [
    "A continuación entrenamos el modelo en nuestro conjunto de datos. Se parece a las funciones de entrenamiento típicas que hemos visto hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "0MbiV_rpo0EC"
   },
   "outputs": [],
   "source": [
    "def train_graph_classifier(model_name, **model_kwargs):\n",
    "    pl.seed_everything(42)\n",
    "\n",
    "    #Creamos el módulo PyTorch Lightning para entrenamiento con retorno\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=500,\n",
    "                         enable_progress_bar=False)\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    #Comprobamos si existe ya el modelo preentrenado, y lo cargamos si es así\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"GraphLevel{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Encontrado un modelo preentrenado, cargando...\")\n",
    "        model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)\n",
    "        model = GraphLevelGNN(c_in=mutag_dataset.num_node_features,\n",
    "                              c_out=1 if mutag_dataset.num_classes==2 else mutag_dataset.num_classes,\n",
    "                              **model_kwargs)\n",
    "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "        model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    #Obtenemos el mejor modelo de test en los conjuntos de validación y de test\n",
    "    train_result = trainer.test(model, graph_train_loader, verbose=False)\n",
    "    test_result = trainer.test(model, graph_test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0]['test_acc'], \"train\": train_result[0]['test_acc']}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC-uRvN_o0EC"
   },
   "source": [
    "Por último, vamos a realizar el entrenamiento y las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihPD2hgWo0EC",
    "outputId": "712d3e60-7e7a-4201-83d2-87cdf5d4c594",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "\n",
      "  | Name        | Type              | Params\n",
      "--------------------------------------------------\n",
      "0 | model       | GraphGNNModel     | 266 K \n",
      "1 | loss_module | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------\n",
      "266 K     Trainable params\n",
      "0         Non-trainable params\n",
      "266 K     Total params\n",
      "1.067     Total estimated model params size (MB)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:490: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "model, result = train_graph_classifier(model_name=\"GraphConv\",\n",
    "                                       c_hidden=256,\n",
    "                                       layer_name=\"GraphConv\",\n",
    "                                       num_layers=3,\n",
    "                                       dp_rate_linear=0.5,\n",
    "                                       dp_rate=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Mp_Udkbo0ED",
    "outputId": "bf0fc819-d843-44d9-f531-877a2add1b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance: 92.76%\n",
      "Test performance:  92.11%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train performance: {100.0*result['train']:4.2f}%\")\n",
    "print(f\"Test performance:  {100.0*result['test']:4.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH_b0jIqo0ED"
   },
   "source": [
    "**Pregunta 5:** ¿Hay overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta Pregunta 5**\n",
    "\n",
    "Rendimiento en el Conjunto de Entrenamiento (Train performance): 92.76%\n",
    "\n",
    "Rendimiento en el Conjunto de Prueba (Test performance): 92.11%\n",
    "\n",
    "Dado que el rendimiento en el conjunto de entrenamiento y en el conjunto de prueba son muy similares y ambos son altos, no hay evidencia significativa de overfitting en este modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEtWZauwm7Yi"
   },
   "source": [
    "**Ejercicio 6:** \"Trastear\" con diferentes capas GNN, hiperparámetros, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "\n",
      "  | Name        | Type              | Params\n",
      "--------------------------------------------------\n",
      "0 | model       | GraphGNNModel     | 34.9 K\n",
      "1 | loss_module | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------\n",
      "34.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.9 K    Total params\n",
      "0.140     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance: 88.73%\n",
      "Test performance:  89.47%\n"
     ]
    }
   ],
   "source": [
    "model, result = train_graph_classifier(model_name=\"GraphConv\",\n",
    "                                       c_hidden=128,\n",
    "                                       num_layers=2,\n",
    "                                       dp_rate_linear=0.3,\n",
    "                                       dp_rate=0.1,\n",
    "                                       layer_name=\"GraphConv\",\n",
    "                                       lr=0.01,\n",
    "                                       weight_decay=0.001)\n",
    "print(f\"Train performance: {100.0*result['train']:4.2f}%\")\n",
    "print(f\"Test performance:  {100.0*result['test']:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "\n",
      "  | Name        | Type              | Params\n",
      "--------------------------------------------------\n",
      "0 | model       | GraphGNNModel     | 298 K \n",
      "1 | loss_module | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------\n",
      "298 K     Trainable params\n",
      "0         Non-trainable params\n",
      "298 K     Total params\n",
      "1.192     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance: 89.20%\n",
      "Test performance:  86.84%\n"
     ]
    }
   ],
   "source": [
    "model, result = train_graph_classifier(model_name=\"GraphConv\",\n",
    "                                       c_hidden=128, # Cambiar el número de unidades ocultas\n",
    "                                       layer_name=\"GraphConv\",\n",
    "                                       num_layers=10, # Cambiar el número de capas\n",
    "                                       dp_rate=0.1, # Ajustar la tasa de dropout en la GNN\n",
    "                                       lr=0.01, # Ajustar la tasa de aprendizaje\n",
    "                                       weight_decay=0.001) # Ajustar el weight decay\n",
    "print(f\"Train performance: {100.0*result['train']:4.2f}%\")\n",
    "print(f\"Test performance:  {100.0*result['test']:4.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ClaS9xl1wsg"
   },
   "source": [
    "## Conclusiones\n",
    "\n",
    "Hemos visto la aplicación de las redes neuronales a las estructuras de grafos. Hemos visto cómo se puede representar un grafo (matriz de adyacencia o lista de aristas), y hemos discutido la implementación de capas de grafos comunes: GCN y GAT. Las implementaciones mostraron el lado práctico de las capas, que a menudo es más sencillo que la teoría. Por último, experimentamos con distintas tareas a nivel de nodos, aristas y grafos. En general, hemos visto que incluir información sobre grafos en las predicciones puede ser crucial para lograr un alto rendimiento. Hay muchas aplicaciones que se benefician de las GNN, y es probable que la importancia de estas redes aumente en los próximos años."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzpy-9LFnTWd"
   },
   "source": [
    "**Ejercicio 7:** Tal y como entiendes inicialmente el concepto de razonamiento computacional bajo incertidumbre, por algún ejemplo de problema real con las GNNs que necesitaría tratar la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta ejercicio 7**\n",
    "Un ejemplo real donde las GNNs podrían necesitar tratar con incertidumbre es en la predicción de interacciones proteína-proteína. Las proteínas interactúan entre sí en una célula para llevar a cabo diversas funciones biológicas, y predecir estas interacciones es crucial para entender los procesos biológicos y desarrollar terapias para enfermedades. \n",
    "(Esto me lo ha explicado mi vecina que trabaja en un laboratorio y no se si realmente sería aplicable con GNNs)\n",
    "Pero se podría desarrollar una GNN que tome en cuenta la incertidumbre en la estructura del grafo y en las características de los nodos."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XPSaU-uRo0Dm",
    "Ml1-ga1Oo0D1",
    "y1sBtVhZo0D-",
    "QSInVvkfo0D-",
    "3ClaS9xl1wsg"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
